{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pycaret[full] in e:\\attrition_application\\venv\\lib\\site-packages (3.3.2)\n",
      "Requirement already satisfied: ipython>=5.5.0 in e:\\attrition_application\\venv\\lib\\site-packages (from pycaret[full]) (9.0.1)\n",
      "Requirement already satisfied: ipywidgets>=7.6.5 in e:\\attrition_application\\venv\\lib\\site-packages (from pycaret[full]) (8.1.5)\n",
      "Requirement already satisfied: tqdm>=4.62.0 in e:\\attrition_application\\venv\\lib\\site-packages (from pycaret[full]) (4.67.1)\n",
      "Requirement already satisfied: numpy<1.27,>=1.21 in e:\\attrition_application\\venv\\lib\\site-packages (from pycaret[full]) (1.26.4)\n",
      "Requirement already satisfied: pandas<2.2.0 in e:\\attrition_application\\venv\\lib\\site-packages (from pycaret[full]) (2.1.4)\n",
      "Requirement already satisfied: jinja2>=3 in e:\\attrition_application\\venv\\lib\\site-packages (from pycaret[full]) (3.1.5)\n",
      "Requirement already satisfied: scipy<=1.11.4,>=1.6.1 in e:\\attrition_application\\venv\\lib\\site-packages (from pycaret[full]) (1.11.4)\n",
      "Requirement already satisfied: joblib<1.4,>=1.2.0 in e:\\attrition_application\\venv\\lib\\site-packages (from pycaret[full]) (1.3.2)\n",
      "Requirement already satisfied: scikit-learn>1.4.0 in e:\\attrition_application\\venv\\lib\\site-packages (from pycaret[full]) (1.4.2)\n",
      "Requirement already satisfied: pyod>=1.1.3 in e:\\attrition_application\\venv\\lib\\site-packages (from pycaret[full]) (2.0.4)\n",
      "Requirement already satisfied: imbalanced-learn>=0.12.0 in e:\\attrition_application\\venv\\lib\\site-packages (from pycaret[full]) (0.13.0)\n",
      "Requirement already satisfied: category-encoders>=2.4.0 in e:\\attrition_application\\venv\\lib\\site-packages (from pycaret[full]) (2.7.0)\n",
      "Requirement already satisfied: lightgbm>=3.0.0 in e:\\attrition_application\\venv\\lib\\site-packages (from pycaret[full]) (4.6.0)\n",
      "Requirement already satisfied: numba>=0.55.0 in e:\\attrition_application\\venv\\lib\\site-packages (from pycaret[full]) (0.61.0)\n",
      "Requirement already satisfied: requests>=2.27.1 in e:\\attrition_application\\venv\\lib\\site-packages (from pycaret[full]) (2.32.3)\n",
      "Requirement already satisfied: psutil>=5.9.0 in e:\\attrition_application\\venv\\lib\\site-packages (from pycaret[full]) (7.0.0)\n",
      "Requirement already satisfied: markupsafe>=2.0.1 in e:\\attrition_application\\venv\\lib\\site-packages (from pycaret[full]) (3.0.2)\n",
      "Requirement already satisfied: importlib-metadata>=4.12.0 in e:\\attrition_application\\venv\\lib\\site-packages (from pycaret[full]) (8.5.0)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in e:\\attrition_application\\venv\\lib\\site-packages (from pycaret[full]) (5.10.4)\n",
      "Requirement already satisfied: cloudpickle in e:\\attrition_application\\venv\\lib\\site-packages (from pycaret[full]) (3.1.1)\n",
      "Requirement already satisfied: deprecation>=2.1.0 in e:\\attrition_application\\venv\\lib\\site-packages (from pycaret[full]) (2.1.0)\n",
      "Requirement already satisfied: xxhash in e:\\attrition_application\\venv\\lib\\site-packages (from pycaret[full]) (3.5.0)\n",
      "Requirement already satisfied: matplotlib<3.8.0 in e:\\attrition_application\\venv\\lib\\site-packages (from pycaret[full]) (3.7.5)\n",
      "Requirement already satisfied: scikit-plot>=0.3.7 in e:\\attrition_application\\venv\\lib\\site-packages (from pycaret[full]) (0.3.7)\n",
      "Requirement already satisfied: yellowbrick>=1.4 in e:\\attrition_application\\venv\\lib\\site-packages (from pycaret[full]) (1.5)\n",
      "Requirement already satisfied: plotly>=5.14.0 in e:\\attrition_application\\venv\\lib\\site-packages (from pycaret[full]) (5.24.1)\n",
      "Requirement already satisfied: kaleido>=0.2.1 in e:\\attrition_application\\venv\\lib\\site-packages (from pycaret[full]) (0.2.1)\n",
      "Requirement already satisfied: schemdraw==0.15 in e:\\attrition_application\\venv\\lib\\site-packages (from pycaret[full]) (0.15)\n",
      "Requirement already satisfied: plotly-resampler>=0.8.3.1 in e:\\attrition_application\\venv\\lib\\site-packages (from pycaret[full]) (0.10.0)\n",
      "Requirement already satisfied: statsmodels>=0.12.1 in e:\\attrition_application\\venv\\lib\\site-packages (from pycaret[full]) (0.14.4)\n",
      "Requirement already satisfied: sktime==0.26.0 in e:\\attrition_application\\venv\\lib\\site-packages (from pycaret[full]) (0.26.0)\n",
      "Requirement already satisfied: tbats>=1.1.3 in e:\\attrition_application\\venv\\lib\\site-packages (from pycaret[full]) (1.1.3)\n",
      "Requirement already satisfied: pmdarima>=2.0.4 in e:\\attrition_application\\venv\\lib\\site-packages (from pycaret[full]) (2.0.4)\n",
      "Requirement already satisfied: shap~=0.44.0 in e:\\attrition_application\\venv\\lib\\site-packages (from pycaret[full]) (0.44.1)\n",
      "Requirement already satisfied: interpret>=0.2.7 in e:\\attrition_application\\venv\\lib\\site-packages (from pycaret[full]) (0.6.10)\n",
      "Requirement already satisfied: umap-learn>=0.5.2 in e:\\attrition_application\\venv\\lib\\site-packages (from pycaret[full]) (0.5.7)\n",
      "Requirement already satisfied: pyyaml in e:\\attrition_application\\venv\\lib\\site-packages (from pycaret[full]) (6.0.2)\n",
      "Requirement already satisfied: ydata-profiling>=4.3.1 in e:\\attrition_application\\venv\\lib\\site-packages (from pycaret[full]) (4.16.1)\n",
      "Requirement already satisfied: explainerdashboard>=0.3.8 in e:\\attrition_application\\venv\\lib\\site-packages (from pycaret[full]) (0.4.8)\n",
      "Requirement already satisfied: fairlearn==0.7.0 in e:\\attrition_application\\venv\\lib\\site-packages (from pycaret[full]) (0.7.0)\n",
      "Requirement already satisfied: kmodes>=0.11.1 in e:\\attrition_application\\venv\\lib\\site-packages (from pycaret[full]) (0.12.2)\n",
      "Requirement already satisfied: mlxtend>=0.19.0 in e:\\attrition_application\\venv\\lib\\site-packages (from pycaret[full]) (0.23.4)\n",
      "Requirement already satisfied: statsforecast<1.6.0,>=0.5.5 in e:\\attrition_application\\venv\\lib\\site-packages (from pycaret[full]) (1.5.0)\n",
      "Requirement already satisfied: hyperopt>=0.2.7 in e:\\attrition_application\\venv\\lib\\site-packages (from pycaret[full]) (0.2.7)\n",
      "Requirement already satisfied: optuna>=3.0.0 in e:\\attrition_application\\venv\\lib\\site-packages (from pycaret[full]) (4.2.1)\n",
      "Requirement already satisfied: optuna-integration in e:\\attrition_application\\venv\\lib\\site-packages (from pycaret[full]) (4.2.1)\n",
      "Requirement already satisfied: scikit-optimize>=0.9.0 in e:\\attrition_application\\venv\\lib\\site-packages (from pycaret[full]) (0.10.2)\n",
      "Requirement already satisfied: mlflow>=2.0.0 in e:\\attrition_application\\venv\\lib\\site-packages (from pycaret[full]) (2.20.3)\n",
      "Requirement already satisfied: gradio>=3.50.2 in e:\\attrition_application\\venv\\lib\\site-packages (from pycaret[full]) (5.23.1)\n",
      "Requirement already satisfied: boto3>=1.24.56 in e:\\attrition_application\\venv\\lib\\site-packages (from pycaret[full]) (1.37.23)\n",
      "Requirement already satisfied: fastapi in e:\\attrition_application\\venv\\lib\\site-packages (from pycaret[full]) (0.115.12)\n",
      "Requirement already satisfied: uvicorn>=0.17.6 in e:\\attrition_application\\venv\\lib\\site-packages (from pycaret[full]) (0.34.0)\n",
      "Requirement already satisfied: m2cgen>=0.9.0 in e:\\attrition_application\\venv\\lib\\site-packages (from pycaret[full]) (0.10.0)\n",
      "Requirement already satisfied: evidently~=0.4.16 in e:\\attrition_application\\venv\\lib\\site-packages (from pycaret[full]) (0.4.40)\n",
      "Requirement already satisfied: dask>=2024.4.1 in e:\\attrition_application\\venv\\lib\\site-packages (from pycaret[full]) (2025.3.0)\n",
      "Requirement already satisfied: distributed>=2024.4.1 in e:\\attrition_application\\venv\\lib\\site-packages (from pycaret[full]) (2025.3.0)\n",
      "Requirement already satisfied: fugue~=0.8.0 in e:\\attrition_application\\venv\\lib\\site-packages (from pycaret[full]) (0.8.7)\n",
      "Requirement already satisfied: flask in e:\\attrition_application\\venv\\lib\\site-packages (from pycaret[full]) (2.3.3)\n",
      "Requirement already satisfied: Werkzeug<3.0,>=2.2 in e:\\attrition_application\\venv\\lib\\site-packages (from pycaret[full]) (2.3.8)\n",
      "Requirement already satisfied: pytest<8.0.0 in e:\\attrition_application\\venv\\lib\\site-packages (from pycaret[full]) (7.4.4)\n",
      "Requirement already satisfied: moto<5.0.0 in e:\\attrition_application\\venv\\lib\\site-packages (from pycaret[full]) (4.2.14)\n",
      "Requirement already satisfied: dash[testing] in e:\\attrition_application\\venv\\lib\\site-packages (from pycaret[full]) (2.18.2)\n",
      "Requirement already satisfied: scikit-learn-intelex>=2023.0.1 in e:\\attrition_application\\venv\\lib\\site-packages (from pycaret[full]) (2025.4.0)\n",
      "Requirement already satisfied: catboost>=0.23.2 in e:\\attrition_application\\venv\\lib\\site-packages (from pycaret[full]) (1.2.7)\n",
      "Requirement already satisfied: packaging in e:\\attrition_application\\venv\\lib\\site-packages (from sktime==0.26.0->pycaret[full]) (24.2)\n",
      "Requirement already satisfied: scikit-base<0.8.0 in e:\\attrition_application\\venv\\lib\\site-packages (from sktime==0.26.0->pycaret[full]) (0.7.8)\n",
      "Requirement already satisfied: botocore<1.38.0,>=1.37.23 in e:\\attrition_application\\venv\\lib\\site-packages (from boto3>=1.24.56->pycaret[full]) (1.37.23)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in e:\\attrition_application\\venv\\lib\\site-packages (from boto3>=1.24.56->pycaret[full]) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.12.0,>=0.11.0 in e:\\attrition_application\\venv\\lib\\site-packages (from boto3>=1.24.56->pycaret[full]) (0.11.4)\n",
      "Requirement already satisfied: graphviz in e:\\attrition_application\\venv\\lib\\site-packages (from catboost>=0.23.2->pycaret[full]) (0.20.3)\n",
      "Requirement already satisfied: six in e:\\attrition_application\\venv\\lib\\site-packages (from catboost>=0.23.2->pycaret[full]) (1.17.0)\n",
      "Requirement already satisfied: patsy>=0.5.1 in e:\\attrition_application\\venv\\lib\\site-packages (from category-encoders>=2.4.0->pycaret[full]) (1.0.1)\n",
      "Requirement already satisfied: click>=8.1 in e:\\attrition_application\\venv\\lib\\site-packages (from dask>=2024.4.1->pycaret[full]) (8.1.8)\n",
      "Requirement already satisfied: fsspec>=2021.09.0 in e:\\attrition_application\\venv\\lib\\site-packages (from dask>=2024.4.1->pycaret[full]) (2025.2.0)\n",
      "Requirement already satisfied: partd>=1.4.0 in e:\\attrition_application\\venv\\lib\\site-packages (from dask>=2024.4.1->pycaret[full]) (1.4.2)\n",
      "Requirement already satisfied: toolz>=0.10.0 in e:\\attrition_application\\venv\\lib\\site-packages (from dask>=2024.4.1->pycaret[full]) (1.0.0)\n",
      "Requirement already satisfied: locket>=1.0.0 in e:\\attrition_application\\venv\\lib\\site-packages (from distributed>=2024.4.1->pycaret[full]) (1.0.0)\n",
      "Requirement already satisfied: msgpack>=1.0.2 in e:\\attrition_application\\venv\\lib\\site-packages (from distributed>=2024.4.1->pycaret[full]) (1.1.0)\n",
      "Requirement already satisfied: sortedcontainers>=2.0.5 in e:\\attrition_application\\venv\\lib\\site-packages (from distributed>=2024.4.1->pycaret[full]) (2.4.0)\n",
      "Requirement already satisfied: tblib>=1.6.0 in e:\\attrition_application\\venv\\lib\\site-packages (from distributed>=2024.4.1->pycaret[full]) (3.0.0)\n",
      "Requirement already satisfied: tornado>=6.2.0 in e:\\attrition_application\\venv\\lib\\site-packages (from distributed>=2024.4.1->pycaret[full]) (6.4.2)\n",
      "Requirement already satisfied: urllib3>=1.26.5 in e:\\attrition_application\\venv\\lib\\site-packages (from distributed>=2024.4.1->pycaret[full]) (1.26.20)\n",
      "Requirement already satisfied: zict>=3.0.0 in e:\\attrition_application\\venv\\lib\\site-packages (from distributed>=2024.4.1->pycaret[full]) (3.0.0)\n",
      "Requirement already satisfied: nltk>=3.6.7 in e:\\attrition_application\\venv\\lib\\site-packages (from evidently~=0.4.16->pycaret[full]) (3.9.1)\n",
      "Requirement already satisfied: pydantic>=1.10.13 in e:\\attrition_application\\venv\\lib\\site-packages (from evidently~=0.4.16->pycaret[full]) (2.10.6)\n",
      "Requirement already satisfied: litestar>=2.8.3 in e:\\attrition_application\\venv\\lib\\site-packages (from evidently~=0.4.16->pycaret[full]) (2.15.1)\n",
      "Requirement already satisfied: typing-inspect>=0.9.0 in e:\\attrition_application\\venv\\lib\\site-packages (from evidently~=0.4.16->pycaret[full]) (0.9.0)\n",
      "Requirement already satisfied: watchdog>=3.0.0 in e:\\attrition_application\\venv\\lib\\site-packages (from evidently~=0.4.16->pycaret[full]) (6.0.0)\n",
      "Requirement already satisfied: typer>=0.3 in e:\\attrition_application\\venv\\lib\\site-packages (from evidently~=0.4.16->pycaret[full]) (0.15.2)\n",
      "Requirement already satisfied: rich>=13 in e:\\attrition_application\\venv\\lib\\site-packages (from evidently~=0.4.16->pycaret[full]) (13.9.4)\n",
      "Requirement already satisfied: iterative-telemetry>=0.0.5 in e:\\attrition_application\\venv\\lib\\site-packages (from evidently~=0.4.16->pycaret[full]) (0.0.10)\n",
      "Requirement already satisfied: dynaconf>=3.2.4 in e:\\attrition_application\\venv\\lib\\site-packages (from evidently~=0.4.16->pycaret[full]) (3.2.10)\n",
      "Requirement already satisfied: certifi>=2024.7.4 in e:\\attrition_application\\venv\\lib\\site-packages (from evidently~=0.4.16->pycaret[full]) (2025.1.31)\n",
      "Requirement already satisfied: ujson>=5.4.0 in e:\\attrition_application\\venv\\lib\\site-packages (from evidently~=0.4.16->pycaret[full]) (5.10.0)\n",
      "Requirement already satisfied: uuid6>=2024.7.10 in e:\\attrition_application\\venv\\lib\\site-packages (from evidently~=0.4.16->pycaret[full]) (2024.7.10)\n",
      "Requirement already satisfied: cryptography>=43.0.1 in e:\\attrition_application\\venv\\lib\\site-packages (from evidently~=0.4.16->pycaret[full]) (44.0.2)\n",
      "Requirement already satisfied: dash-auth in e:\\attrition_application\\venv\\lib\\site-packages (from explainerdashboard>=0.3.8->pycaret[full]) (2.3.0)\n",
      "Requirement already satisfied: dash-bootstrap-components>=1 in e:\\attrition_application\\venv\\lib\\site-packages (from explainerdashboard>=0.3.8->pycaret[full]) (1.7.1)\n",
      "Requirement already satisfied: dtreeviz>=2.1 in e:\\attrition_application\\venv\\lib\\site-packages (from explainerdashboard>=0.3.8->pycaret[full]) (2.2.2)\n",
      "Requirement already satisfied: flask_simplelogin in e:\\attrition_application\\venv\\lib\\site-packages (from explainerdashboard>=0.3.8->pycaret[full]) (0.2.0)\n",
      "Requirement already satisfied: Flask-WTF>=1.1 in e:\\attrition_application\\venv\\lib\\site-packages (from explainerdashboard>=0.3.8->pycaret[full]) (1.2.2)\n",
      "Requirement already satisfied: jupyter_dash>=0.4.1 in e:\\attrition_application\\venv\\lib\\site-packages (from explainerdashboard>=0.3.8->pycaret[full]) (0.4.2)\n",
      "Requirement already satisfied: oyaml in e:\\attrition_application\\venv\\lib\\site-packages (from explainerdashboard>=0.3.8->pycaret[full]) (1.0)\n",
      "Requirement already satisfied: waitress in e:\\attrition_application\\venv\\lib\\site-packages (from explainerdashboard>=0.3.8->pycaret[full]) (3.0.2)\n",
      "Requirement already satisfied: triad>=0.9.3 in e:\\attrition_application\\venv\\lib\\site-packages (from fugue~=0.8.0->pycaret[full]) (0.9.8)\n",
      "Requirement already satisfied: adagio>=0.2.4 in e:\\attrition_application\\venv\\lib\\site-packages (from fugue~=0.8.0->pycaret[full]) (0.2.6)\n",
      "Requirement already satisfied: qpd>=0.4.4 in e:\\attrition_application\\venv\\lib\\site-packages (from fugue~=0.8.0->pycaret[full]) (0.4.4)\n",
      "Requirement already satisfied: fugue-sql-antlr>=0.1.6 in e:\\attrition_application\\venv\\lib\\site-packages (from fugue~=0.8.0->pycaret[full]) (0.2.2)\n",
      "Requirement already satisfied: sqlglot in e:\\attrition_application\\venv\\lib\\site-packages (from fugue~=0.8.0->pycaret[full]) (26.12.0)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in e:\\attrition_application\\venv\\lib\\site-packages (from gradio>=3.50.2->pycaret[full]) (23.2.1)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in e:\\attrition_application\\venv\\lib\\site-packages (from gradio>=3.50.2->pycaret[full]) (4.8.0)\n",
      "Requirement already satisfied: ffmpy in e:\\attrition_application\\venv\\lib\\site-packages (from gradio>=3.50.2->pycaret[full]) (0.5.0)\n",
      "Requirement already satisfied: gradio-client==1.8.0 in e:\\attrition_application\\venv\\lib\\site-packages (from gradio>=3.50.2->pycaret[full]) (1.8.0)\n",
      "Requirement already satisfied: groovy~=0.1 in e:\\attrition_application\\venv\\lib\\site-packages (from gradio>=3.50.2->pycaret[full]) (0.1.2)\n",
      "Requirement already satisfied: httpx>=0.24.1 in e:\\attrition_application\\venv\\lib\\site-packages (from gradio>=3.50.2->pycaret[full]) (0.28.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.28.1 in e:\\attrition_application\\venv\\lib\\site-packages (from gradio>=3.50.2->pycaret[full]) (0.29.3)\n",
      "Requirement already satisfied: orjson~=3.0 in e:\\attrition_application\\venv\\lib\\site-packages (from gradio>=3.50.2->pycaret[full]) (3.10.16)\n",
      "Requirement already satisfied: pillow<12.0,>=8.0 in e:\\attrition_application\\venv\\lib\\site-packages (from gradio>=3.50.2->pycaret[full]) (11.1.0)\n",
      "Requirement already satisfied: pydub in e:\\attrition_application\\venv\\lib\\site-packages (from gradio>=3.50.2->pycaret[full]) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.18 in e:\\attrition_application\\venv\\lib\\site-packages (from gradio>=3.50.2->pycaret[full]) (0.0.20)\n",
      "Requirement already satisfied: ruff>=0.9.3 in e:\\attrition_application\\venv\\lib\\site-packages (from gradio>=3.50.2->pycaret[full]) (0.11.2)\n",
      "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in e:\\attrition_application\\venv\\lib\\site-packages (from gradio>=3.50.2->pycaret[full]) (0.1.6)\n",
      "Requirement already satisfied: semantic-version~=2.0 in e:\\attrition_application\\venv\\lib\\site-packages (from gradio>=3.50.2->pycaret[full]) (2.10.0)\n",
      "Requirement already satisfied: starlette<1.0,>=0.40.0 in e:\\attrition_application\\venv\\lib\\site-packages (from gradio>=3.50.2->pycaret[full]) (0.46.1)\n",
      "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in e:\\attrition_application\\venv\\lib\\site-packages (from gradio>=3.50.2->pycaret[full]) (0.13.2)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in e:\\attrition_application\\venv\\lib\\site-packages (from gradio>=3.50.2->pycaret[full]) (4.12.2)\n",
      "Requirement already satisfied: websockets<16.0,>=10.0 in e:\\attrition_application\\venv\\lib\\site-packages (from gradio-client==1.8.0->gradio>=3.50.2->pycaret[full]) (15.0)\n",
      "Requirement already satisfied: networkx>=2.2 in e:\\attrition_application\\venv\\lib\\site-packages (from hyperopt>=0.2.7->pycaret[full]) (3.4.2)\n",
      "Requirement already satisfied: future in e:\\attrition_application\\venv\\lib\\site-packages (from hyperopt>=0.2.7->pycaret[full]) (1.0.0)\n",
      "Requirement already satisfied: py4j in e:\\attrition_application\\venv\\lib\\site-packages (from hyperopt>=0.2.7->pycaret[full]) (0.10.9.9)\n",
      "Requirement already satisfied: sklearn-compat<1,>=0.1 in e:\\attrition_application\\venv\\lib\\site-packages (from imbalanced-learn>=0.12.0->pycaret[full]) (0.1.3)\n",
      "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in e:\\attrition_application\\venv\\lib\\site-packages (from imbalanced-learn>=0.12.0->pycaret[full]) (3.5.0)\n",
      "Requirement already satisfied: zipp>=3.20 in e:\\attrition_application\\venv\\lib\\site-packages (from importlib-metadata>=4.12.0->pycaret[full]) (3.21.0)\n",
      "Requirement already satisfied: interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10 in e:\\attrition_application\\venv\\lib\\site-packages (from interpret>=0.2.7->pycaret[full]) (0.6.10)\n",
      "Requirement already satisfied: ipykernel>=4.10.0 in e:\\attrition_application\\venv\\lib\\site-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret>=0.2.7->pycaret[full]) (6.29.5)\n",
      "Requirement already satisfied: SALib>=1.3.3 in e:\\attrition_application\\venv\\lib\\site-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret>=0.2.7->pycaret[full]) (1.5.1)\n",
      "Requirement already satisfied: dill>=0.2.5 in e:\\attrition_application\\venv\\lib\\site-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret>=0.2.7->pycaret[full]) (0.3.9)\n",
      "Requirement already satisfied: aplr>=10.6.1 in e:\\attrition_application\\venv\\lib\\site-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret>=0.2.7->pycaret[full]) (10.8.0)\n",
      "Requirement already satisfied: dash-core-components>=1.0.0 in e:\\attrition_application\\venv\\lib\\site-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret>=0.2.7->pycaret[full]) (2.0.0)\n",
      "Requirement already satisfied: dash-html-components>=1.0.0 in e:\\attrition_application\\venv\\lib\\site-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret>=0.2.7->pycaret[full]) (2.0.0)\n",
      "Requirement already satisfied: dash-table>=4.1.0 in e:\\attrition_application\\venv\\lib\\site-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret>=0.2.7->pycaret[full]) (5.0.0)\n",
      "Requirement already satisfied: dash-cytoscape>=0.1.1 in e:\\attrition_application\\venv\\lib\\site-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret>=0.2.7->pycaret[full]) (1.0.2)\n",
      "Requirement already satisfied: gevent>=1.3.6 in e:\\attrition_application\\venv\\lib\\site-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret>=0.2.7->pycaret[full]) (24.11.1)\n",
      "Requirement already satisfied: colorama in e:\\attrition_application\\venv\\lib\\site-packages (from ipython>=5.5.0->pycaret[full]) (0.4.6)\n",
      "Requirement already satisfied: decorator in e:\\attrition_application\\venv\\lib\\site-packages (from ipython>=5.5.0->pycaret[full]) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in e:\\attrition_application\\venv\\lib\\site-packages (from ipython>=5.5.0->pycaret[full]) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in e:\\attrition_application\\venv\\lib\\site-packages (from ipython>=5.5.0->pycaret[full]) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in e:\\attrition_application\\venv\\lib\\site-packages (from ipython>=5.5.0->pycaret[full]) (0.1.7)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in e:\\attrition_application\\venv\\lib\\site-packages (from ipython>=5.5.0->pycaret[full]) (3.0.50)\n",
      "Requirement already satisfied: pygments>=2.4.0 in e:\\attrition_application\\venv\\lib\\site-packages (from ipython>=5.5.0->pycaret[full]) (2.19.1)\n",
      "Requirement already satisfied: stack_data in e:\\attrition_application\\venv\\lib\\site-packages (from ipython>=5.5.0->pycaret[full]) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in e:\\attrition_application\\venv\\lib\\site-packages (from ipython>=5.5.0->pycaret[full]) (5.14.3)\n",
      "Requirement already satisfied: comm>=0.1.3 in e:\\attrition_application\\venv\\lib\\site-packages (from ipywidgets>=7.6.5->pycaret[full]) (0.2.2)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in e:\\attrition_application\\venv\\lib\\site-packages (from ipywidgets>=7.6.5->pycaret[full]) (4.0.13)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in e:\\attrition_application\\venv\\lib\\site-packages (from ipywidgets>=7.6.5->pycaret[full]) (3.0.13)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in e:\\attrition_application\\venv\\lib\\site-packages (from matplotlib<3.8.0->pycaret[full]) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in e:\\attrition_application\\venv\\lib\\site-packages (from matplotlib<3.8.0->pycaret[full]) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in e:\\attrition_application\\venv\\lib\\site-packages (from matplotlib<3.8.0->pycaret[full]) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in e:\\attrition_application\\venv\\lib\\site-packages (from matplotlib<3.8.0->pycaret[full]) (1.4.8)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in e:\\attrition_application\\venv\\lib\\site-packages (from matplotlib<3.8.0->pycaret[full]) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in e:\\attrition_application\\venv\\lib\\site-packages (from matplotlib<3.8.0->pycaret[full]) (2.9.0.post0)\n",
      "Requirement already satisfied: mlflow-skinny==2.20.3 in e:\\attrition_application\\venv\\lib\\site-packages (from mlflow>=2.0.0->pycaret[full]) (2.20.3)\n",
      "Requirement already satisfied: alembic!=1.10.0,<2 in e:\\attrition_application\\venv\\lib\\site-packages (from mlflow>=2.0.0->pycaret[full]) (1.15.1)\n",
      "Requirement already satisfied: docker<8,>=4.0.0 in e:\\attrition_application\\venv\\lib\\site-packages (from mlflow>=2.0.0->pycaret[full]) (7.1.0)\n",
      "Requirement already satisfied: graphene<4 in e:\\attrition_application\\venv\\lib\\site-packages (from mlflow>=2.0.0->pycaret[full]) (3.4.3)\n",
      "Requirement already satisfied: markdown<4,>=3.3 in e:\\attrition_application\\venv\\lib\\site-packages (from mlflow>=2.0.0->pycaret[full]) (3.7)\n",
      "Requirement already satisfied: pyarrow<20,>=4.0.0 in e:\\attrition_application\\venv\\lib\\site-packages (from mlflow>=2.0.0->pycaret[full]) (19.0.1)\n",
      "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in e:\\attrition_application\\venv\\lib\\site-packages (from mlflow>=2.0.0->pycaret[full]) (2.0.38)\n",
      "Requirement already satisfied: cachetools<6,>=5.0.0 in e:\\attrition_application\\venv\\lib\\site-packages (from mlflow-skinny==2.20.3->mlflow>=2.0.0->pycaret[full]) (5.5.2)\n",
      "Requirement already satisfied: databricks-sdk<1,>=0.20.0 in e:\\attrition_application\\venv\\lib\\site-packages (from mlflow-skinny==2.20.3->mlflow>=2.0.0->pycaret[full]) (0.45.0)\n",
      "Requirement already satisfied: gitpython<4,>=3.1.9 in e:\\attrition_application\\venv\\lib\\site-packages (from mlflow-skinny==2.20.3->mlflow>=2.0.0->pycaret[full]) (3.1.44)\n",
      "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in e:\\attrition_application\\venv\\lib\\site-packages (from mlflow-skinny==2.20.3->mlflow>=2.0.0->pycaret[full]) (1.30.0)\n",
      "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in e:\\attrition_application\\venv\\lib\\site-packages (from mlflow-skinny==2.20.3->mlflow>=2.0.0->pycaret[full]) (1.30.0)\n",
      "Requirement already satisfied: protobuf<6,>=3.12.0 in e:\\attrition_application\\venv\\lib\\site-packages (from mlflow-skinny==2.20.3->mlflow>=2.0.0->pycaret[full]) (5.29.3)\n",
      "Requirement already satisfied: sqlparse<1,>=0.4.0 in e:\\attrition_application\\venv\\lib\\site-packages (from mlflow-skinny==2.20.3->mlflow>=2.0.0->pycaret[full]) (0.5.3)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in e:\\attrition_application\\venv\\lib\\site-packages (from flask->pycaret[full]) (2.2.0)\n",
      "Requirement already satisfied: blinker>=1.6.2 in e:\\attrition_application\\venv\\lib\\site-packages (from flask->pycaret[full]) (1.9.0)\n",
      "Requirement already satisfied: xmltodict in e:\\attrition_application\\venv\\lib\\site-packages (from moto<5.0.0->pycaret[full]) (0.14.2)\n",
      "Requirement already satisfied: responses>=0.13.0 in e:\\attrition_application\\venv\\lib\\site-packages (from moto<5.0.0->pycaret[full]) (0.25.7)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in e:\\attrition_application\\venv\\lib\\site-packages (from nbformat>=4.2.0->pycaret[full]) (2.21.1)\n",
      "Requirement already satisfied: jsonschema>=2.6 in e:\\attrition_application\\venv\\lib\\site-packages (from nbformat>=4.2.0->pycaret[full]) (4.23.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in e:\\attrition_application\\venv\\lib\\site-packages (from nbformat>=4.2.0->pycaret[full]) (5.7.2)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in e:\\attrition_application\\venv\\lib\\site-packages (from numba>=0.55.0->pycaret[full]) (0.44.0)\n",
      "Requirement already satisfied: colorlog in e:\\attrition_application\\venv\\lib\\site-packages (from optuna>=3.0.0->pycaret[full]) (6.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in e:\\attrition_application\\venv\\lib\\site-packages (from pandas<2.2.0->pycaret[full]) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in e:\\attrition_application\\venv\\lib\\site-packages (from pandas<2.2.0->pycaret[full]) (2025.1)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in e:\\attrition_application\\venv\\lib\\site-packages (from plotly>=5.14.0->pycaret[full]) (9.0.0)\n",
      "Requirement already satisfied: tsdownsample>=0.1.3 in e:\\attrition_application\\venv\\lib\\site-packages (from plotly-resampler>=0.8.3.1->pycaret[full]) (0.1.4.1)\n",
      "Requirement already satisfied: Cython!=0.29.18,!=0.29.31,>=0.29 in e:\\attrition_application\\venv\\lib\\site-packages (from pmdarima>=2.0.4->pycaret[full]) (3.0.12)\n",
      "Requirement already satisfied: setuptools!=50.0.0,>=38.6.0 in e:\\attrition_application\\venv\\lib\\site-packages (from pmdarima>=2.0.4->pycaret[full]) (65.5.0)\n",
      "Requirement already satisfied: iniconfig in e:\\attrition_application\\venv\\lib\\site-packages (from pytest<8.0.0->pycaret[full]) (2.1.0)\n",
      "Requirement already satisfied: pluggy<2.0,>=0.12 in e:\\attrition_application\\venv\\lib\\site-packages (from pytest<8.0.0->pycaret[full]) (1.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\attrition_application\\venv\\lib\\site-packages (from requests>=2.27.1->pycaret[full]) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\attrition_application\\venv\\lib\\site-packages (from requests>=2.27.1->pycaret[full]) (3.10)\n",
      "Requirement already satisfied: daal==2025.4.0 in e:\\attrition_application\\venv\\lib\\site-packages (from scikit-learn-intelex>=2023.0.1->pycaret[full]) (2025.4.0)\n",
      "Requirement already satisfied: tbb==2022.* in e:\\attrition_application\\venv\\lib\\site-packages (from daal==2025.4.0->scikit-learn-intelex>=2023.0.1->pycaret[full]) (2022.1.0)\n",
      "Requirement already satisfied: tcmlib==1.* in e:\\attrition_application\\venv\\lib\\site-packages (from tbb==2022.*->daal==2025.4.0->scikit-learn-intelex>=2023.0.1->pycaret[full]) (1.3.0)\n",
      "Requirement already satisfied: pyaml>=16.9 in e:\\attrition_application\\venv\\lib\\site-packages (from scikit-optimize>=0.9.0->pycaret[full]) (25.1.0)\n",
      "Requirement already satisfied: slicer==0.0.7 in e:\\attrition_application\\venv\\lib\\site-packages (from shap~=0.44.0->pycaret[full]) (0.0.7)\n",
      "Requirement already satisfied: pynndescent>=0.5 in e:\\attrition_application\\venv\\lib\\site-packages (from umap-learn>=0.5.2->pycaret[full]) (0.5.13)\n",
      "Requirement already satisfied: h11>=0.8 in e:\\attrition_application\\venv\\lib\\site-packages (from uvicorn>=0.17.6->pycaret[full]) (0.14.0)\n",
      "Requirement already satisfied: visions[type_image_path]<0.8.2,>=0.7.5 in e:\\attrition_application\\venv\\lib\\site-packages (from ydata-profiling>=4.3.1->pycaret[full]) (0.8.1)\n",
      "Requirement already satisfied: htmlmin==0.1.12 in e:\\attrition_application\\venv\\lib\\site-packages (from ydata-profiling>=4.3.1->pycaret[full]) (0.1.12)\n",
      "Requirement already satisfied: phik<0.13,>=0.11.1 in e:\\attrition_application\\venv\\lib\\site-packages (from ydata-profiling>=4.3.1->pycaret[full]) (0.12.4)\n",
      "Requirement already satisfied: seaborn<0.14,>=0.10.1 in e:\\attrition_application\\venv\\lib\\site-packages (from ydata-profiling>=4.3.1->pycaret[full]) (0.13.2)\n",
      "Requirement already satisfied: multimethod<2,>=1.4 in e:\\attrition_application\\venv\\lib\\site-packages (from ydata-profiling>=4.3.1->pycaret[full]) (1.12)\n",
      "Requirement already satisfied: typeguard<5,>=3 in e:\\attrition_application\\venv\\lib\\site-packages (from ydata-profiling>=4.3.1->pycaret[full]) (4.4.2)\n",
      "Requirement already satisfied: imagehash==4.3.1 in e:\\attrition_application\\venv\\lib\\site-packages (from ydata-profiling>=4.3.1->pycaret[full]) (4.3.1)\n",
      "Requirement already satisfied: wordcloud>=1.9.3 in e:\\attrition_application\\venv\\lib\\site-packages (from ydata-profiling>=4.3.1->pycaret[full]) (1.9.4)\n",
      "Requirement already satisfied: dacite>=1.8 in e:\\attrition_application\\venv\\lib\\site-packages (from ydata-profiling>=4.3.1->pycaret[full]) (1.9.2)\n",
      "Requirement already satisfied: PyWavelets in e:\\attrition_application\\venv\\lib\\site-packages (from imagehash==4.3.1->ydata-profiling>=4.3.1->pycaret[full]) (1.8.0)\n",
      "Requirement already satisfied: retrying in e:\\attrition_application\\venv\\lib\\site-packages (from dash[testing]->pycaret[full]) (1.3.4)\n",
      "Requirement already satisfied: nest-asyncio in e:\\attrition_application\\venv\\lib\\site-packages (from dash[testing]->pycaret[full]) (1.6.0)\n",
      "Requirement already satisfied: beautifulsoup4>=4.8.2 in e:\\attrition_application\\venv\\lib\\site-packages (from dash[testing]->pycaret[full]) (4.13.3)\n",
      "Requirement already satisfied: lxml>=4.6.2 in e:\\attrition_application\\venv\\lib\\site-packages (from dash[testing]->pycaret[full]) (5.3.1)\n",
      "Requirement already satisfied: percy>=2.0.2 in e:\\attrition_application\\venv\\lib\\site-packages (from dash[testing]->pycaret[full]) (2.0.2)\n",
      "Requirement already satisfied: selenium<=4.2.0,>=3.141.0 in e:\\attrition_application\\venv\\lib\\site-packages (from dash[testing]->pycaret[full]) (4.2.0)\n",
      "Requirement already satisfied: multiprocess>=0.70.12 in e:\\attrition_application\\venv\\lib\\site-packages (from dash[testing]->pycaret[full]) (0.70.17)\n",
      "Requirement already satisfied: dash-testing-stub>=0.0.2 in e:\\attrition_application\\venv\\lib\\site-packages (from dash[testing]->pycaret[full]) (0.0.2)\n",
      "Requirement already satisfied: Mako in e:\\attrition_application\\venv\\lib\\site-packages (from alembic!=1.10.0,<2->mlflow>=2.0.0->pycaret[full]) (1.3.9)\n",
      "Requirement already satisfied: sniffio>=1.1 in e:\\attrition_application\\venv\\lib\\site-packages (from anyio<5.0,>=3.0->gradio>=3.50.2->pycaret[full]) (1.3.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in e:\\attrition_application\\venv\\lib\\site-packages (from beautifulsoup4>=4.8.2->dash[testing]->pycaret[full]) (2.6)\n",
      "Requirement already satisfied: cffi>=1.12 in e:\\attrition_application\\venv\\lib\\site-packages (from cryptography>=43.0.1->evidently~=0.4.16->pycaret[full]) (1.17.1)\n",
      "Requirement already satisfied: pywin32>=304 in e:\\attrition_application\\venv\\lib\\site-packages (from docker<8,>=4.0.0->mlflow>=2.0.0->pycaret[full]) (308)\n",
      "Requirement already satisfied: colour in e:\\attrition_application\\venv\\lib\\site-packages (from dtreeviz>=2.1->explainerdashboard>=0.3.8->pycaret[full]) (0.1.5)\n",
      "Requirement already satisfied: wtforms in e:\\attrition_application\\venv\\lib\\site-packages (from Flask-WTF>=1.1->explainerdashboard>=0.3.8->pycaret[full]) (3.2.1)\n",
      "Requirement already satisfied: antlr4-python3-runtime<4.12 in e:\\attrition_application\\venv\\lib\\site-packages (from fugue-sql-antlr>=0.1.6->fugue~=0.8.0->pycaret[full]) (4.11.1)\n",
      "Requirement already satisfied: graphql-core<3.3,>=3.1 in e:\\attrition_application\\venv\\lib\\site-packages (from graphene<4->mlflow>=2.0.0->pycaret[full]) (3.2.6)\n",
      "Requirement already satisfied: graphql-relay<3.3,>=3.1 in e:\\attrition_application\\venv\\lib\\site-packages (from graphene<4->mlflow>=2.0.0->pycaret[full]) (3.2.0)\n",
      "Requirement already satisfied: httpcore==1.* in e:\\attrition_application\\venv\\lib\\site-packages (from httpx>=0.24.1->gradio>=3.50.2->pycaret[full]) (1.0.7)\n",
      "Requirement already satisfied: filelock in e:\\attrition_application\\venv\\lib\\site-packages (from huggingface-hub>=0.28.1->gradio>=3.50.2->pycaret[full]) (3.17.0)\n",
      "Requirement already satisfied: appdirs in e:\\attrition_application\\venv\\lib\\site-packages (from iterative-telemetry>=0.0.5->evidently~=0.4.16->pycaret[full]) (1.4.4)\n",
      "Requirement already satisfied: distro in e:\\attrition_application\\venv\\lib\\site-packages (from iterative-telemetry>=0.0.5->evidently~=0.4.16->pycaret[full]) (1.9.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in e:\\attrition_application\\venv\\lib\\site-packages (from jedi>=0.16->ipython>=5.5.0->pycaret[full]) (0.8.4)\n",
      "Requirement already satisfied: attrs>=22.2.0 in e:\\attrition_application\\venv\\lib\\site-packages (from jsonschema>=2.6->nbformat>=4.2.0->pycaret[full]) (25.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in e:\\attrition_application\\venv\\lib\\site-packages (from jsonschema>=2.6->nbformat>=4.2.0->pycaret[full]) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in e:\\attrition_application\\venv\\lib\\site-packages (from jsonschema>=2.6->nbformat>=4.2.0->pycaret[full]) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in e:\\attrition_application\\venv\\lib\\site-packages (from jsonschema>=2.6->nbformat>=4.2.0->pycaret[full]) (0.23.1)\n",
      "Requirement already satisfied: platformdirs>=2.5 in e:\\attrition_application\\venv\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->nbformat>=4.2.0->pycaret[full]) (4.3.6)\n",
      "Requirement already satisfied: ansi2html in e:\\attrition_application\\venv\\lib\\site-packages (from jupyter_dash>=0.4.1->explainerdashboard>=0.3.8->pycaret[full]) (1.9.2)\n",
      "Requirement already satisfied: litestar-htmx>=0.4.0 in e:\\attrition_application\\venv\\lib\\site-packages (from litestar>=2.8.3->evidently~=0.4.16->pycaret[full]) (0.4.1)\n",
      "Requirement already satisfied: msgspec>=0.18.2 in e:\\attrition_application\\venv\\lib\\site-packages (from litestar>=2.8.3->evidently~=0.4.16->pycaret[full]) (0.19.0)\n",
      "Requirement already satisfied: multidict>=6.0.2 in e:\\attrition_application\\venv\\lib\\site-packages (from litestar>=2.8.3->evidently~=0.4.16->pycaret[full]) (6.1.0)\n",
      "Requirement already satisfied: multipart>=1.2.0 in e:\\attrition_application\\venv\\lib\\site-packages (from litestar>=2.8.3->evidently~=0.4.16->pycaret[full]) (1.2.1)\n",
      "Requirement already satisfied: polyfactory>=2.6.3 in e:\\attrition_application\\venv\\lib\\site-packages (from litestar>=2.8.3->evidently~=0.4.16->pycaret[full]) (2.19.0)\n",
      "Requirement already satisfied: rich-click in e:\\attrition_application\\venv\\lib\\site-packages (from litestar>=2.8.3->evidently~=0.4.16->pycaret[full]) (1.8.6)\n",
      "Requirement already satisfied: regex>=2021.8.3 in e:\\attrition_application\\venv\\lib\\site-packages (from nltk>=3.6.7->evidently~=0.4.16->pycaret[full]) (2024.11.6)\n",
      "Requirement already satisfied: wcwidth in e:\\attrition_application\\venv\\lib\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=5.5.0->pycaret[full]) (0.2.13)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in e:\\attrition_application\\venv\\lib\\site-packages (from pydantic>=1.10.13->evidently~=0.4.16->pycaret[full]) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in e:\\attrition_application\\venv\\lib\\site-packages (from pydantic>=1.10.13->evidently~=0.4.16->pycaret[full]) (2.27.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in e:\\attrition_application\\venv\\lib\\site-packages (from rich>=13->evidently~=0.4.16->pycaret[full]) (3.0.0)\n",
      "Requirement already satisfied: trio~=0.17 in e:\\attrition_application\\venv\\lib\\site-packages (from selenium<=4.2.0,>=3.141.0->dash[testing]->pycaret[full]) (0.29.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in e:\\attrition_application\\venv\\lib\\site-packages (from selenium<=4.2.0,>=3.141.0->dash[testing]->pycaret[full]) (0.12.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in e:\\attrition_application\\venv\\lib\\site-packages (from sqlalchemy<3,>=1.4.0->mlflow>=2.0.0->pycaret[full]) (3.1.1)\n",
      "Requirement already satisfied: fs in e:\\attrition_application\\venv\\lib\\site-packages (from triad>=0.9.3->fugue~=0.8.0->pycaret[full]) (2.4.16)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in e:\\attrition_application\\venv\\lib\\site-packages (from typer>=0.3->evidently~=0.4.16->pycaret[full]) (1.5.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in e:\\attrition_application\\venv\\lib\\site-packages (from typing-inspect>=0.9.0->evidently~=0.4.16->pycaret[full]) (1.0.0)\n",
      "Requirement already satisfied: httptools>=0.6.3 in e:\\attrition_application\\venv\\lib\\site-packages (from uvicorn>=0.17.6->pycaret[full]) (0.6.4)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in e:\\attrition_application\\venv\\lib\\site-packages (from uvicorn>=0.17.6->pycaret[full]) (1.0.1)\n",
      "Requirement already satisfied: watchfiles>=0.13 in e:\\attrition_application\\venv\\lib\\site-packages (from uvicorn>=0.17.6->pycaret[full]) (1.0.4)\n",
      "Requirement already satisfied: puremagic in e:\\attrition_application\\venv\\lib\\site-packages (from visions[type_image_path]<0.8.2,>=0.7.5->ydata-profiling>=4.3.1->pycaret[full]) (1.28)\n",
      "Requirement already satisfied: executing>=1.2.0 in e:\\attrition_application\\venv\\lib\\site-packages (from stack_data->ipython>=5.5.0->pycaret[full]) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in e:\\attrition_application\\venv\\lib\\site-packages (from stack_data->ipython>=5.5.0->pycaret[full]) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in e:\\attrition_application\\venv\\lib\\site-packages (from stack_data->ipython>=5.5.0->pycaret[full]) (0.2.3)\n",
      "Requirement already satisfied: pycparser in e:\\attrition_application\\venv\\lib\\site-packages (from cffi>=1.12->cryptography>=43.0.1->evidently~=0.4.16->pycaret[full]) (2.22)\n",
      "Requirement already satisfied: google-auth~=2.0 in e:\\attrition_application\\venv\\lib\\site-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.20.3->mlflow>=2.0.0->pycaret[full]) (2.38.0)\n",
      "Requirement already satisfied: zope.event in e:\\attrition_application\\venv\\lib\\site-packages (from gevent>=1.3.6->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret>=0.2.7->pycaret[full]) (5.0)\n",
      "Requirement already satisfied: zope.interface in e:\\attrition_application\\venv\\lib\\site-packages (from gevent>=1.3.6->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret>=0.2.7->pycaret[full]) (7.2)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in e:\\attrition_application\\venv\\lib\\site-packages (from gitpython<4,>=3.1.9->mlflow-skinny==2.20.3->mlflow>=2.0.0->pycaret[full]) (4.0.12)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in e:\\attrition_application\\venv\\lib\\site-packages (from ipykernel>=4.10.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret>=0.2.7->pycaret[full]) (1.8.12)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in e:\\attrition_application\\venv\\lib\\site-packages (from ipykernel>=4.10.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret>=0.2.7->pycaret[full]) (8.6.3)\n",
      "Requirement already satisfied: pyzmq>=24 in e:\\attrition_application\\venv\\lib\\site-packages (from ipykernel>=4.10.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.10->interpret>=0.2.7->pycaret[full]) (26.2.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in e:\\attrition_application\\venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=13->evidently~=0.4.16->pycaret[full]) (0.1.2)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in e:\\attrition_application\\venv\\lib\\site-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.20.3->mlflow>=2.0.0->pycaret[full]) (1.2.18)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.51b0 in e:\\attrition_application\\venv\\lib\\site-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.20.3->mlflow>=2.0.0->pycaret[full]) (0.51b0)\n",
      "Requirement already satisfied: faker in e:\\attrition_application\\venv\\lib\\site-packages (from polyfactory>=2.6.3->litestar>=2.8.3->evidently~=0.4.16->pycaret[full]) (36.1.1)\n",
      "Requirement already satisfied: outcome in e:\\attrition_application\\venv\\lib\\site-packages (from trio~=0.17->selenium<=4.2.0,>=3.141.0->dash[testing]->pycaret[full]) (1.3.0.post0)\n",
      "Requirement already satisfied: wsproto>=0.14 in e:\\attrition_application\\venv\\lib\\site-packages (from trio-websocket~=0.9->selenium<=4.2.0,>=3.141.0->dash[testing]->pycaret[full]) (1.2.0)\n",
      "Requirement already satisfied: pyOpenSSL>=0.14 in e:\\attrition_application\\venv\\lib\\site-packages (from urllib3>=1.26.5->distributed>=2024.4.1->pycaret[full]) (25.0.0)\n",
      "Requirement already satisfied: urllib3-secure-extra in e:\\attrition_application\\venv\\lib\\site-packages (from urllib3>=1.26.5->distributed>=2024.4.1->pycaret[full]) (0.1.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in e:\\attrition_application\\venv\\lib\\site-packages (from urllib3>=1.26.5->distributed>=2024.4.1->pycaret[full]) (1.7.1)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in e:\\attrition_application\\venv\\lib\\site-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.20.3->mlflow>=2.0.0->pycaret[full]) (1.17.2)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in e:\\attrition_application\\venv\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.20.3->mlflow>=2.0.0->pycaret[full]) (5.0.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in e:\\attrition_application\\venv\\lib\\site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.20.3->mlflow>=2.0.0->pycaret[full]) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in e:\\attrition_application\\venv\\lib\\site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.20.3->mlflow>=2.0.0->pycaret[full]) (4.9)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in e:\\attrition_application\\venv\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.20.3->mlflow>=2.0.0->pycaret[full]) (0.6.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: visions 0.8.1 does not provide the extra 'type_image_path'\n",
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pycaret[full]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: optuna in e:\\attrition_application\\venv\\lib\\site-packages (4.2.1)\n",
      "Requirement already satisfied: alembic>=1.5.0 in e:\\attrition_application\\venv\\lib\\site-packages (from optuna) (1.15.1)\n",
      "Requirement already satisfied: colorlog in e:\\attrition_application\\venv\\lib\\site-packages (from optuna) (6.9.0)\n",
      "Requirement already satisfied: numpy in e:\\attrition_application\\venv\\lib\\site-packages (from optuna) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in e:\\attrition_application\\venv\\lib\\site-packages (from optuna) (24.2)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in e:\\attrition_application\\venv\\lib\\site-packages (from optuna) (2.0.38)\n",
      "Requirement already satisfied: tqdm in e:\\attrition_application\\venv\\lib\\site-packages (from optuna) (4.67.1)\n",
      "Requirement already satisfied: PyYAML in e:\\attrition_application\\venv\\lib\\site-packages (from optuna) (6.0.2)\n",
      "Requirement already satisfied: Mako in e:\\attrition_application\\venv\\lib\\site-packages (from alembic>=1.5.0->optuna) (1.3.9)\n",
      "Requirement already satisfied: typing-extensions>=4.12 in e:\\attrition_application\\venv\\lib\\site-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in e:\\attrition_application\\venv\\lib\\site-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n",
      "Requirement already satisfied: colorama in e:\\attrition_application\\venv\\lib\\site-packages (from colorlog->optuna) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in e:\\attrition_application\\venv\\lib\\site-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install optuna "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import mlflow\n",
    "from sklearn.metrics import roc_auc_score,balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Path('/').resolve()\n",
    "X_directory = Path('Attrition_Application\\/artifacts\\data_transformed_artifact\\X_train_trfm.csv')\n",
    "y_directory = Path('Attrition_Application\\/artifacts\\data_transformed_artifact\\Y_train_trfm.csv')\n",
    "X = Path.joinpath(root,X_directory)\n",
    "Y = Path.joinpath(root,y_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv(X,header=None)\n",
    "y = pd.read_csv(Y,header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = X\n",
    "data['target'] = y[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns = [str(feature) for feature in X.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.classification import ClassificationExperiment\n",
    "exp = ClassificationExperiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_23b4b_row9_col1 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_23b4b\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_23b4b_level0_col0\" class=\"col_heading level0 col0\" >Description</th>\n",
       "      <th id=\"T_23b4b_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_23b4b_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_23b4b_row0_col0\" class=\"data row0 col0\" >Session id</td>\n",
       "      <td id=\"T_23b4b_row0_col1\" class=\"data row0 col1\" >123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_23b4b_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_23b4b_row1_col0\" class=\"data row1 col0\" >Target</td>\n",
       "      <td id=\"T_23b4b_row1_col1\" class=\"data row1 col1\" >target</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_23b4b_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_23b4b_row2_col0\" class=\"data row2 col0\" >Target type</td>\n",
       "      <td id=\"T_23b4b_row2_col1\" class=\"data row2 col1\" >Binary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_23b4b_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_23b4b_row3_col0\" class=\"data row3 col0\" >Original data shape</td>\n",
       "      <td id=\"T_23b4b_row3_col1\" class=\"data row3 col1\" >(1967, 26)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_23b4b_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_23b4b_row4_col0\" class=\"data row4 col0\" >Transformed data shape</td>\n",
       "      <td id=\"T_23b4b_row4_col1\" class=\"data row4 col1\" >(1967, 26)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_23b4b_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_23b4b_row5_col0\" class=\"data row5 col0\" >Transformed train set shape</td>\n",
       "      <td id=\"T_23b4b_row5_col1\" class=\"data row5 col1\" >(1376, 26)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_23b4b_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_23b4b_row6_col0\" class=\"data row6 col0\" >Transformed test set shape</td>\n",
       "      <td id=\"T_23b4b_row6_col1\" class=\"data row6 col1\" >(591, 26)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_23b4b_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_23b4b_row7_col0\" class=\"data row7 col0\" >Numeric features</td>\n",
       "      <td id=\"T_23b4b_row7_col1\" class=\"data row7 col1\" >25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_23b4b_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_23b4b_row8_col0\" class=\"data row8 col0\" >Rows with missing values</td>\n",
       "      <td id=\"T_23b4b_row8_col1\" class=\"data row8 col1\" >0.1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_23b4b_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_23b4b_row9_col0\" class=\"data row9 col0\" >Preprocess</td>\n",
       "      <td id=\"T_23b4b_row9_col1\" class=\"data row9 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_23b4b_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_23b4b_row10_col0\" class=\"data row10 col0\" >Imputation type</td>\n",
       "      <td id=\"T_23b4b_row10_col1\" class=\"data row10 col1\" >simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_23b4b_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_23b4b_row11_col0\" class=\"data row11 col0\" >Numeric imputation</td>\n",
       "      <td id=\"T_23b4b_row11_col1\" class=\"data row11 col1\" >mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_23b4b_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_23b4b_row12_col0\" class=\"data row12 col0\" >Categorical imputation</td>\n",
       "      <td id=\"T_23b4b_row12_col1\" class=\"data row12 col1\" >mode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_23b4b_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_23b4b_row13_col0\" class=\"data row13 col0\" >Fold Generator</td>\n",
       "      <td id=\"T_23b4b_row13_col1\" class=\"data row13 col1\" >StratifiedKFold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_23b4b_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_23b4b_row14_col0\" class=\"data row14 col0\" >Fold Number</td>\n",
       "      <td id=\"T_23b4b_row14_col1\" class=\"data row14 col1\" >10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_23b4b_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_23b4b_row15_col0\" class=\"data row15 col0\" >CPU Jobs</td>\n",
       "      <td id=\"T_23b4b_row15_col1\" class=\"data row15 col1\" >-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_23b4b_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_23b4b_row16_col0\" class=\"data row16 col0\" >Use GPU</td>\n",
       "      <td id=\"T_23b4b_row16_col1\" class=\"data row16 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_23b4b_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_23b4b_row17_col0\" class=\"data row17 col0\" >Log Experiment</td>\n",
       "      <td id=\"T_23b4b_row17_col1\" class=\"data row17 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_23b4b_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_23b4b_row18_col0\" class=\"data row18 col0\" >Experiment Name</td>\n",
       "      <td id=\"T_23b4b_row18_col1\" class=\"data row18 col1\" >clf-default-name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_23b4b_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_23b4b_row19_col0\" class=\"data row19 col0\" >USI</td>\n",
       "      <td id=\"T_23b4b_row19_col1\" class=\"data row19 col1\" >e252</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1c689fbd110>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<pycaret.classification.oop.ClassificationExperiment at 0x1c68537ac90>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# init setup on exp\n",
    "exp.setup(data, target = 'target', session_id = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Reference</th>\n",
       "      <th>Turbo</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lr</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>sklearn.linear_model._logistic.LogisticRegression</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn</th>\n",
       "      <td>K Neighbors Classifier</td>\n",
       "      <td>sklearn.neighbors._classification.KNeighborsCl...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nb</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>sklearn.naive_bayes.GaussianNB</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dt</th>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>sklearn.tree._classes.DecisionTreeClassifier</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm</th>\n",
       "      <td>SVM - Linear Kernel</td>\n",
       "      <td>sklearn.linear_model._stochastic_gradient.SGDC...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rbfsvm</th>\n",
       "      <td>SVM - Radial Kernel</td>\n",
       "      <td>sklearn.svm._classes.SVC</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpc</th>\n",
       "      <td>Gaussian Process Classifier</td>\n",
       "      <td>sklearn.gaussian_process._gpc.GaussianProcessC...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>MLP Classifier</td>\n",
       "      <td>sklearn.neural_network._multilayer_perceptron....</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ridge</th>\n",
       "      <td>Ridge Classifier</td>\n",
       "      <td>sklearn.linear_model._ridge.RidgeClassifier</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>sklearn.ensemble._forest.RandomForestClassifier</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qda</th>\n",
       "      <td>Quadratic Discriminant Analysis</td>\n",
       "      <td>sklearn.discriminant_analysis.QuadraticDiscrim...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ada</th>\n",
       "      <td>Ada Boost Classifier</td>\n",
       "      <td>sklearn.ensemble._weight_boosting.AdaBoostClas...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gbc</th>\n",
       "      <td>Gradient Boosting Classifier</td>\n",
       "      <td>sklearn.ensemble._gb.GradientBoostingClassifier</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lda</th>\n",
       "      <td>Linear Discriminant Analysis</td>\n",
       "      <td>sklearn.discriminant_analysis.LinearDiscrimina...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>et</th>\n",
       "      <td>Extra Trees Classifier</td>\n",
       "      <td>sklearn.ensemble._forest.ExtraTreesClassifier</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lightgbm</th>\n",
       "      <td>Light Gradient Boosting Machine</td>\n",
       "      <td>lightgbm.sklearn.LGBMClassifier</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>catboost</th>\n",
       "      <td>CatBoost Classifier</td>\n",
       "      <td>catboost.core.CatBoostClassifier</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dummy</th>\n",
       "      <td>Dummy Classifier</td>\n",
       "      <td>sklearn.dummy.DummyClassifier</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Name  \\\n",
       "ID                                          \n",
       "lr                    Logistic Regression   \n",
       "knn                K Neighbors Classifier   \n",
       "nb                            Naive Bayes   \n",
       "dt               Decision Tree Classifier   \n",
       "svm                   SVM - Linear Kernel   \n",
       "rbfsvm                SVM - Radial Kernel   \n",
       "gpc           Gaussian Process Classifier   \n",
       "mlp                        MLP Classifier   \n",
       "ridge                    Ridge Classifier   \n",
       "rf               Random Forest Classifier   \n",
       "qda       Quadratic Discriminant Analysis   \n",
       "ada                  Ada Boost Classifier   \n",
       "gbc          Gradient Boosting Classifier   \n",
       "lda          Linear Discriminant Analysis   \n",
       "et                 Extra Trees Classifier   \n",
       "lightgbm  Light Gradient Boosting Machine   \n",
       "catboost              CatBoost Classifier   \n",
       "dummy                    Dummy Classifier   \n",
       "\n",
       "                                                  Reference  Turbo  \n",
       "ID                                                                  \n",
       "lr        sklearn.linear_model._logistic.LogisticRegression   True  \n",
       "knn       sklearn.neighbors._classification.KNeighborsCl...   True  \n",
       "nb                           sklearn.naive_bayes.GaussianNB   True  \n",
       "dt             sklearn.tree._classes.DecisionTreeClassifier   True  \n",
       "svm       sklearn.linear_model._stochastic_gradient.SGDC...   True  \n",
       "rbfsvm                             sklearn.svm._classes.SVC  False  \n",
       "gpc       sklearn.gaussian_process._gpc.GaussianProcessC...  False  \n",
       "mlp       sklearn.neural_network._multilayer_perceptron....  False  \n",
       "ridge           sklearn.linear_model._ridge.RidgeClassifier   True  \n",
       "rf          sklearn.ensemble._forest.RandomForestClassifier   True  \n",
       "qda       sklearn.discriminant_analysis.QuadraticDiscrim...   True  \n",
       "ada       sklearn.ensemble._weight_boosting.AdaBoostClas...   True  \n",
       "gbc         sklearn.ensemble._gb.GradientBoostingClassifier   True  \n",
       "lda       sklearn.discriminant_analysis.LinearDiscrimina...   True  \n",
       "et            sklearn.ensemble._forest.ExtraTreesClassifier   True  \n",
       "lightgbm                    lightgbm.sklearn.LGBMClassifier   True  \n",
       "catboost                   catboost.core.CatBoostClassifier   True  \n",
       "dummy                         sklearn.dummy.DummyClassifier   True  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_d710a th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_d710a_row0_col0, #T_d710a_row0_col3, #T_d710a_row0_col4, #T_d710a_row1_col0, #T_d710a_row1_col1, #T_d710a_row1_col2, #T_d710a_row1_col3, #T_d710a_row1_col5, #T_d710a_row1_col6, #T_d710a_row1_col7, #T_d710a_row2_col0, #T_d710a_row2_col1, #T_d710a_row2_col2, #T_d710a_row2_col3, #T_d710a_row2_col4, #T_d710a_row2_col5, #T_d710a_row2_col6, #T_d710a_row2_col7, #T_d710a_row3_col0, #T_d710a_row3_col1, #T_d710a_row3_col2, #T_d710a_row3_col4, #T_d710a_row3_col5, #T_d710a_row3_col6, #T_d710a_row3_col7 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_d710a_row0_col1, #T_d710a_row0_col2, #T_d710a_row0_col5, #T_d710a_row0_col6, #T_d710a_row0_col7, #T_d710a_row1_col4, #T_d710a_row3_col3 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "}\n",
       "#T_d710a_row0_col8 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "#T_d710a_row1_col8, #T_d710a_row2_col8, #T_d710a_row3_col8 {\n",
       "  text-align: left;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_d710a\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_d710a_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_d710a_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_d710a_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
       "      <th id=\"T_d710a_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_d710a_level0_col4\" class=\"col_heading level0 col4\" >Prec.</th>\n",
       "      <th id=\"T_d710a_level0_col5\" class=\"col_heading level0 col5\" >F1</th>\n",
       "      <th id=\"T_d710a_level0_col6\" class=\"col_heading level0 col6\" >Kappa</th>\n",
       "      <th id=\"T_d710a_level0_col7\" class=\"col_heading level0 col7\" >MCC</th>\n",
       "      <th id=\"T_d710a_level0_col8\" class=\"col_heading level0 col8\" >TT (Sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_d710a_level0_row0\" class=\"row_heading level0 row0\" >rf</th>\n",
       "      <td id=\"T_d710a_row0_col0\" class=\"data row0 col0\" >Random Forest Classifier</td>\n",
       "      <td id=\"T_d710a_row0_col1\" class=\"data row0 col1\" >0.9164</td>\n",
       "      <td id=\"T_d710a_row0_col2\" class=\"data row0 col2\" >0.9588</td>\n",
       "      <td id=\"T_d710a_row0_col3\" class=\"data row0 col3\" >0.8619</td>\n",
       "      <td id=\"T_d710a_row0_col4\" class=\"data row0 col4\" >0.9680</td>\n",
       "      <td id=\"T_d710a_row0_col5\" class=\"data row0 col5\" >0.9113</td>\n",
       "      <td id=\"T_d710a_row0_col6\" class=\"data row0 col6\" >0.8328</td>\n",
       "      <td id=\"T_d710a_row0_col7\" class=\"data row0 col7\" >0.8385</td>\n",
       "      <td id=\"T_d710a_row0_col8\" class=\"data row0 col8\" >0.1680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d710a_level0_row1\" class=\"row_heading level0 row1\" >gbc</th>\n",
       "      <td id=\"T_d710a_row1_col0\" class=\"data row1 col0\" >Gradient Boosting Classifier</td>\n",
       "      <td id=\"T_d710a_row1_col1\" class=\"data row1 col1\" >0.9157</td>\n",
       "      <td id=\"T_d710a_row1_col2\" class=\"data row1 col2\" >0.9550</td>\n",
       "      <td id=\"T_d710a_row1_col3\" class=\"data row1 col3\" >0.8575</td>\n",
       "      <td id=\"T_d710a_row1_col4\" class=\"data row1 col4\" >0.9703</td>\n",
       "      <td id=\"T_d710a_row1_col5\" class=\"data row1 col5\" >0.9101</td>\n",
       "      <td id=\"T_d710a_row1_col6\" class=\"data row1 col6\" >0.8313</td>\n",
       "      <td id=\"T_d710a_row1_col7\" class=\"data row1 col7\" >0.8374</td>\n",
       "      <td id=\"T_d710a_row1_col8\" class=\"data row1 col8\" >0.2260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d710a_level0_row2\" class=\"row_heading level0 row2\" >lr</th>\n",
       "      <td id=\"T_d710a_row2_col0\" class=\"data row2 col0\" >Logistic Regression</td>\n",
       "      <td id=\"T_d710a_row2_col1\" class=\"data row2 col1\" >0.8641</td>\n",
       "      <td id=\"T_d710a_row2_col2\" class=\"data row2 col2\" >0.9340</td>\n",
       "      <td id=\"T_d710a_row2_col3\" class=\"data row2 col3\" >0.8488</td>\n",
       "      <td id=\"T_d710a_row2_col4\" class=\"data row2 col4\" >0.8761</td>\n",
       "      <td id=\"T_d710a_row2_col5\" class=\"data row2 col5\" >0.8619</td>\n",
       "      <td id=\"T_d710a_row2_col6\" class=\"data row2 col6\" >0.7282</td>\n",
       "      <td id=\"T_d710a_row2_col7\" class=\"data row2 col7\" >0.7290</td>\n",
       "      <td id=\"T_d710a_row2_col8\" class=\"data row2 col8\" >2.6700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d710a_level0_row3\" class=\"row_heading level0 row3\" >dt</th>\n",
       "      <td id=\"T_d710a_row3_col0\" class=\"data row3 col0\" >Decision Tree Classifier</td>\n",
       "      <td id=\"T_d710a_row3_col1\" class=\"data row3 col1\" >0.8597</td>\n",
       "      <td id=\"T_d710a_row3_col2\" class=\"data row3 col2\" >0.8597</td>\n",
       "      <td id=\"T_d710a_row3_col3\" class=\"data row3 col3\" >0.8749</td>\n",
       "      <td id=\"T_d710a_row3_col4\" class=\"data row3 col4\" >0.8490</td>\n",
       "      <td id=\"T_d710a_row3_col5\" class=\"data row3 col5\" >0.8616</td>\n",
       "      <td id=\"T_d710a_row3_col6\" class=\"data row3 col6\" >0.7194</td>\n",
       "      <td id=\"T_d710a_row3_col7\" class=\"data row3 col7\" >0.7201</td>\n",
       "      <td id=\"T_d710a_row3_col8\" class=\"data row3 col8\" >1.8400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1c68b8afe10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_models = exp.compare_models(include=['lr','dt','rf','gbc'],cross_validation=True,fold=5,n_select=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                        criterion='gini', max_depth=None, max_features='sqrt',\n",
       "                        max_leaf_nodes=None, max_samples=None,\n",
       "                        min_impurity_decrease=0.0, min_samples_leaf=1,\n",
       "                        min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                        monotonic_cst=None, n_estimators=100, n_jobs=-1,\n",
       "                        oob_score=False, random_state=123, verbose=0,\n",
       "                        warm_start=False),\n",
       " GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
       "                            learning_rate=0.1, loss='log_loss', max_depth=3,\n",
       "                            max_features=None, max_leaf_nodes=None,\n",
       "                            min_impurity_decrease=0.0, min_samples_leaf=1,\n",
       "                            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                            n_estimators=100, n_iter_no_change=None,\n",
       "                            random_state=123, subsample=1.0, tol=0.0001,\n",
       "                            validation_fraction=0.1, verbose=0,\n",
       "                            warm_start=False),\n",
       " LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                    intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
       "                    multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                    random_state=123, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                    warm_start=False)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dict = {\n",
    "               'LogisticRegression': LogisticRegression,\n",
    "               'RandomForestClassifier': RandomForestClassifier, \n",
    "               'DecisionTreeClassifier': DecisionTreeClassifier,\n",
    "               'SGDClassifier':SGDClassifier,\n",
    "               'GradientBoostingClassifier':GradientBoostingClassifier\n",
    "               }\n",
    "\n",
    "\n",
    "\n",
    "top_models = [models_dict[model.__class__.__name__] for model in best_models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[sklearn.ensemble._forest.RandomForestClassifier,\n",
       " sklearn.ensemble._gb.GradientBoostingClassifier,\n",
       " sklearn.linear_model._logistic.LogisticRegression]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LogisticRegObj(trial):\n",
    "  lr_C = trial.suggest_uniform('C', 0.0, 1.0)\n",
    "\n",
    "  classifier_obj = LogisticRegression(C=lr_C)\n",
    "  classifier_obj = classifier_obj.fit(X,y)\n",
    "  pred = classifier_obj.predict(X)\n",
    "  score = roc_auc_score(y,pred)\n",
    "\n",
    "  return score\n",
    "\n",
    "def RandomForObj(trial):\n",
    "  rfc_n_estimators = trial.suggest_int('n_estimators', 50, 250, 25)\n",
    "  rfc_criterion = trial.suggest_categorical(\"criterion\", [\"gini\", \"entropy\", \"log_loss\"])\n",
    "  rfc_min_samples_split  = trial.suggest_uniform('min_samples_split',0.2, 1.0)\n",
    "  rfc_max_depth = trial.suggest_int('max_depth', 2, 10, 2)\n",
    "\n",
    "  classifier_obj = RandomForestClassifier(\n",
    "                                   n_estimators=rfc_n_estimators,\n",
    "                                   criterion=rfc_criterion,\n",
    "                                   min_samples_split = rfc_min_samples_split,\n",
    "                                   max_depth = rfc_max_depth\n",
    "                                   )\n",
    "  classifier_obj = classifier_obj.fit(X,y)\n",
    "  \n",
    "  pred = classifier_obj.predict(X)\n",
    "  score = roc_auc_score(y,pred)\n",
    "\n",
    "  return score\n",
    "\n",
    "def SGDRegObj(trial):\n",
    "    sgd_eta0 = trial.suggest_uniform('eta0',0.1, 1.0)\n",
    "\n",
    "    sgd_loss = trial.suggest_categorical('loss', ['hinge',\n",
    "                                                      'log_loss',\n",
    "                                                      'modified_huber',\n",
    "                                                      'squared_hinge',\n",
    "                                                      'perceptron',\n",
    "                                                      'squared_error',\n",
    "                                                      'huber'])\n",
    "    sgd_learning_rate = trial.suggest_categorical('learning_rate', ['constant',\n",
    "                                                      'optimal',\n",
    "                                                      'invscaling',\n",
    "                                                      'adaptive'])\n",
    "\n",
    "    classifier_obj = SGDClassifier(loss=sgd_loss,\n",
    "                                       eta0 = sgd_eta0,\n",
    "                                       learning_rate=sgd_learning_rate)\n",
    "\n",
    "    classifier_obj = classifier_obj.fit(X,y)\n",
    "    pred = classifier_obj.predict(X)\n",
    "    score = roc_auc_score(y,pred)\n",
    "\n",
    "    return score\n",
    "\n",
    "def DecisionTreeClassObj(trial):\n",
    "    criterion = trial.suggest_categorical(\"criterion\", [\"log_loss\", \"gini\",'entropy'])\n",
    "    max_depth = trial.suggest_int(\n",
    "          \"n_estimators\", 3, 8, 1\n",
    "      )\n",
    "    \n",
    "    subsample = trial.suggest_float(\n",
    "          \"subsample\", 0.3, 0.9, log=True\n",
    "      )\n",
    "    \n",
    "    min_samples_leaf = trial.suggest_float(\n",
    "        \"min_samples_leaf\", 0.3, 0.9, log=True\n",
    "    )\n",
    "\n",
    "    min_samples_split = trial.suggest_float(\n",
    "          \"min_samples_split\", 0.3, 0.9, log=True\n",
    "    )\n",
    "    \n",
    "    classifier_obj = DecisionTreeClassifier(\n",
    "                                        criterion = criterion,\n",
    "                                        max_depth=max_depth,  \n",
    "                                        min_samples_split = min_samples_split,\n",
    "                                        subsample=subsample,\n",
    "                                        min_samples_leaf=min_samples_leaf\n",
    "                                        )\n",
    "\n",
    "    classifier_obj = classifier_obj.fit(X,y)\n",
    "    pred = classifier_obj.predict(X)\n",
    "    score = roc_auc_score(y,pred)\n",
    "\n",
    "    return score\n",
    "\n",
    "\n",
    "def GradientBoostClassObj(trial):\n",
    "  loss = trial.suggest_categorical(\"loss\", [\"log_loss\", \"exponential\"])\n",
    "  max_depth = trial.suggest_int(\n",
    "          \"n_estimators\", 3, 8, 1\n",
    "      )\n",
    "  learning_rate = trial.suggest_float(\n",
    "        \"learning_rate\", 0.0005, 0.05, log=True\n",
    "    )\n",
    "  n_estimators = trial.suggest_int(\n",
    "        \"n_estimators\", 50, 350, 50\n",
    "    )\n",
    "   \n",
    "  subsample = trial.suggest_float(\n",
    "        \"subsample\", 0.3, 0.9, log=True\n",
    "    )\n",
    "   \n",
    "  min_samples_leaf = trial.suggest_float(\n",
    "        \"min_samples_leaf\", 0.3, 0.9, log=True\n",
    "  )\n",
    "\n",
    "  min_samples_split = trial.suggest_float(\n",
    "        \"min_samples_split\", 0.3, 0.9, log=True\n",
    "  )\n",
    "   \n",
    "  classifier_obj = GradientBoostingClassifier(\n",
    "                                       n_estimators = n_estimators,\n",
    "                                       max_depth=max_depth,\n",
    "                                       loss=loss,\n",
    "                                       learning_rate = learning_rate,\n",
    "                                       subsample=subsample,\n",
    "                                       min_samples_split=min_samples_split,\n",
    "                                       min_samples_leaf=min_samples_leaf\n",
    "                                       )\n",
    "\n",
    "  classifier_obj = classifier_obj.fit(X,y)\n",
    "  pred = classifier_obj.predict(X)\n",
    "  score = roc_auc_score(y,pred)\n",
    "\n",
    "  return score\n",
    "\n",
    "objectives = {\n",
    "    'LogisticRegression':LogisticRegObj,\n",
    "    'RandomForestClassifier': RandomForObj,\n",
    "    'SGDClassifier': SGDRegObj,\n",
    "    'GradientBoostingClassifier':GradientBoostClassObj,\n",
    "    'DecisionTreeClassifier': DecisionTreeClassObj\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 17:38:46,043] A new study created in memory with name: no-name-51e44249-3c9a-4f4e-b53e-51d2121f64ab\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 17:38:46,202] Trial 0 finished with value: 0.9923702950152594 and parameters: {'n_estimators': 75, 'criterion': 'log_loss', 'min_samples_split': 0.4566050979741286, 'max_depth': 8}. Best is trial 0 with value: 0.9923702950152594.\n",
      "[I 2025-03-29 17:38:46,602] Trial 1 finished with value: 1.0 and parameters: {'n_estimators': 225, 'criterion': 'entropy', 'min_samples_split': 0.3694658609314691, 'max_depth': 4}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:38:46,900] Trial 2 finished with value: 0.9847405900305188 and parameters: {'n_estimators': 175, 'criterion': 'log_loss', 'min_samples_split': 0.5556842733693363, 'max_depth': 4}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:38:46,994] Trial 3 finished with value: 1.0 and parameters: {'n_estimators': 50, 'criterion': 'gini', 'min_samples_split': 0.229954079522755, 'max_depth': 10}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:38:47,148] Trial 4 finished with value: 0.5 and parameters: {'n_estimators': 100, 'criterion': 'gini', 'min_samples_split': 0.7365064797925076, 'max_depth': 8}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:38:47,434] Trial 5 finished with value: 0.9918616480162767 and parameters: {'n_estimators': 150, 'criterion': 'gini', 'min_samples_split': 0.35119327224432473, 'max_depth': 2}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:38:47,592] Trial 6 finished with value: 0.9923702950152594 and parameters: {'n_estimators': 75, 'criterion': 'gini', 'min_samples_split': 0.44838170259501803, 'max_depth': 6}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:38:47,764] Trial 7 finished with value: 0.5 and parameters: {'n_estimators': 100, 'criterion': 'entropy', 'min_samples_split': 0.9116380408875402, 'max_depth': 4}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:38:48,075] Trial 8 finished with value: 0.5 and parameters: {'n_estimators': 200, 'criterion': 'gini', 'min_samples_split': 0.7095367220099662, 'max_depth': 6}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:38:48,323] Trial 9 finished with value: 0.9852497539471834 and parameters: {'n_estimators': 125, 'criterion': 'gini', 'min_samples_split': 0.3615103437532161, 'max_depth': 2}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:38:48,845] Trial 10 finished with value: 1.0 and parameters: {'n_estimators': 250, 'criterion': 'entropy', 'min_samples_split': 0.2234572200531545, 'max_depth': 4}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:38:49,351] Trial 11 finished with value: 1.0 and parameters: {'n_estimators': 250, 'criterion': 'entropy', 'min_samples_split': 0.20208978569081215, 'max_depth': 10}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:38:49,474] Trial 12 finished with value: 1.0 and parameters: {'n_estimators': 50, 'criterion': 'entropy', 'min_samples_split': 0.31158666504988025, 'max_depth': 10}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:38:49,858] Trial 13 finished with value: 0.9888097660223805 and parameters: {'n_estimators': 200, 'criterion': 'entropy', 'min_samples_split': 0.44642792495915656, 'max_depth': 8}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:38:50,272] Trial 14 finished with value: 0.9888097660223805 and parameters: {'n_estimators': 225, 'criterion': 'log_loss', 'min_samples_split': 0.5832143164188398, 'max_depth': 4}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:38:50,552] Trial 15 finished with value: 1.0 and parameters: {'n_estimators': 150, 'criterion': 'gini', 'min_samples_split': 0.2901501131762543, 'max_depth': 10}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:38:50,647] Trial 16 finished with value: 0.5 and parameters: {'n_estimators': 50, 'criterion': 'entropy', 'min_samples_split': 0.9644977489810886, 'max_depth': 6}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:38:51,039] Trial 17 finished with value: 0.984231943031536 and parameters: {'n_estimators': 200, 'criterion': 'gini', 'min_samples_split': 0.5013792925041254, 'max_depth': 8}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:38:51,257] Trial 18 finished with value: 0.5 and parameters: {'n_estimators': 150, 'criterion': 'entropy', 'min_samples_split': 0.6991057484906592, 'max_depth': 6}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:38:51,790] Trial 19 finished with value: 0.984231943031536 and parameters: {'n_estimators': 225, 'criterion': 'log_loss', 'min_samples_split': 0.2748317729221513, 'max_depth': 2}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:38:52,047] Trial 20 finished with value: 0.996439471007121 and parameters: {'n_estimators': 125, 'criterion': 'entropy', 'min_samples_split': 0.3813033572601606, 'max_depth': 4}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:38:52,576] Trial 21 finished with value: 1.0 and parameters: {'n_estimators': 250, 'criterion': 'entropy', 'min_samples_split': 0.22198729897490357, 'max_depth': 4}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:38:53,068] Trial 22 finished with value: 1.0 and parameters: {'n_estimators': 225, 'criterion': 'entropy', 'min_samples_split': 0.23794665085992717, 'max_depth': 4}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:38:53,610] Trial 23 finished with value: 1.0 and parameters: {'n_estimators': 250, 'criterion': 'entropy', 'min_samples_split': 0.31530248011292905, 'max_depth': 2}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:38:54,000] Trial 24 finished with value: 0.9760935910478128 and parameters: {'n_estimators': 175, 'criterion': 'entropy', 'min_samples_split': 0.403878311628595, 'max_depth': 4}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:38:54,530] Trial 25 finished with value: 1.0 and parameters: {'n_estimators': 225, 'criterion': 'gini', 'min_samples_split': 0.2083643239930579, 'max_depth': 6}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:38:55,113] Trial 26 finished with value: 0.9944048830111902 and parameters: {'n_estimators': 250, 'criterion': 'entropy', 'min_samples_split': 0.2639729241082662, 'max_depth': 6}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:38:55,504] Trial 27 finished with value: 0.9908443540183113 and parameters: {'n_estimators': 175, 'criterion': 'entropy', 'min_samples_split': 0.5172653089053824, 'max_depth': 2}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:38:55,936] Trial 28 finished with value: 1.0 and parameters: {'n_estimators': 200, 'criterion': 'log_loss', 'min_samples_split': 0.3252611002900002, 'max_depth': 4}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:38:56,124] Trial 29 finished with value: 1.0 and parameters: {'n_estimators': 100, 'criterion': 'gini', 'min_samples_split': 0.6409155224299411, 'max_depth': 8}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:38:56,373] Trial 30 finished with value: 0.9852492370295015 and parameters: {'n_estimators': 125, 'criterion': 'log_loss', 'min_samples_split': 0.41853905430407223, 'max_depth': 10}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:38:56,956] Trial 31 finished with value: 1.0 and parameters: {'n_estimators': 250, 'criterion': 'entropy', 'min_samples_split': 0.22098287187622406, 'max_depth': 10}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:38:57,587] Trial 32 finished with value: 1.0 and parameters: {'n_estimators': 250, 'criterion': 'entropy', 'min_samples_split': 0.20765018114680114, 'max_depth': 10}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:38:58,062] Trial 33 finished with value: 1.0 and parameters: {'n_estimators': 225, 'criterion': 'entropy', 'min_samples_split': 0.27205067361457586, 'max_depth': 10}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:38:58,610] Trial 34 finished with value: 0.9989827060020346 and parameters: {'n_estimators': 250, 'criterion': 'entropy', 'min_samples_split': 0.3477492613223073, 'max_depth': 10}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:38:58,995] Trial 35 finished with value: 1.0 and parameters: {'n_estimators': 225, 'criterion': 'gini', 'min_samples_split': 0.265821923945317, 'max_depth': 8}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:38:59,124] Trial 36 finished with value: 0.5 and parameters: {'n_estimators': 75, 'criterion': 'entropy', 'min_samples_split': 0.7892391320029866, 'max_depth': 8}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:38:59,412] Trial 37 finished with value: 0.9933875890132249 and parameters: {'n_estimators': 175, 'criterion': 'gini', 'min_samples_split': 0.5118410735781451, 'max_depth': 6}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:38:59,880] Trial 38 finished with value: 0.991353001017294 and parameters: {'n_estimators': 250, 'criterion': 'log_loss', 'min_samples_split': 0.36881455022007326, 'max_depth': 4}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:00,286] Trial 39 finished with value: 0.9928789420142421 and parameters: {'n_estimators': 200, 'criterion': 'entropy', 'min_samples_split': 0.3174376265800133, 'max_depth': 8}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:00,391] Trial 40 finished with value: 0.9923702950152594 and parameters: {'n_estimators': 50, 'criterion': 'gini', 'min_samples_split': 0.24483609468360623, 'max_depth': 2}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:00,500] Trial 41 finished with value: 0.9984740590030519 and parameters: {'n_estimators': 50, 'criterion': 'entropy', 'min_samples_split': 0.30051198763210635, 'max_depth': 10}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:00,661] Trial 42 finished with value: 1.0 and parameters: {'n_estimators': 75, 'criterion': 'entropy', 'min_samples_split': 0.3389287207477754, 'max_depth': 10}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:00,765] Trial 43 finished with value: 0.991353001017294 and parameters: {'n_estimators': 50, 'criterion': 'entropy', 'min_samples_split': 0.4631833183017322, 'max_depth': 10}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:00,986] Trial 44 finished with value: 1.0 and parameters: {'n_estimators': 100, 'criterion': 'entropy', 'min_samples_split': 0.2049110278330964, 'max_depth': 10}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:01,175] Trial 45 finished with value: 0.9938962360122074 and parameters: {'n_estimators': 75, 'criterion': 'entropy', 'min_samples_split': 0.2931769568702015, 'max_depth': 8}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:01,351] Trial 46 finished with value: 0.991353001017294 and parameters: {'n_estimators': 100, 'criterion': 'gini', 'min_samples_split': 0.4084296536129166, 'max_depth': 10}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:01,514] Trial 47 finished with value: 1.0 and parameters: {'n_estimators': 50, 'criterion': 'entropy', 'min_samples_split': 0.24300528838815794, 'max_depth': 6}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:01,922] Trial 48 finished with value: 0.9832146490335707 and parameters: {'n_estimators': 225, 'criterion': 'entropy', 'min_samples_split': 0.4656665180410356, 'max_depth': 4}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:02,107] Trial 49 finished with value: 0.9888097660223805 and parameters: {'n_estimators': 75, 'criterion': 'log_loss', 'min_samples_split': 0.37111069271394526, 'max_depth': 10}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:02,397] Trial 50 finished with value: 0.5 and parameters: {'n_estimators': 200, 'criterion': 'gini', 'min_samples_split': 0.812184400279085, 'max_depth': 4}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:02,683] Trial 51 finished with value: 0.9954221770091556 and parameters: {'n_estimators': 150, 'criterion': 'gini', 'min_samples_split': 0.283147967130686, 'max_depth': 10}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:02,917] Trial 52 finished with value: 1.0 and parameters: {'n_estimators': 125, 'criterion': 'gini', 'min_samples_split': 0.24309327930114322, 'max_depth': 8}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:03,215] Trial 53 finished with value: 0.9944048830111902 and parameters: {'n_estimators': 150, 'criterion': 'gini', 'min_samples_split': 0.3010682429895951, 'max_depth': 10}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:03,728] Trial 54 finished with value: 0.9974567650050865 and parameters: {'n_estimators': 250, 'criterion': 'gini', 'min_samples_split': 0.2544589727576193, 'max_depth': 10}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:04,149] Trial 55 finished with value: 0.9933875890132249 and parameters: {'n_estimators': 225, 'criterion': 'entropy', 'min_samples_split': 0.3380302603617261, 'max_depth': 8}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:04,488] Trial 56 finished with value: 0.9928789420142421 and parameters: {'n_estimators': 175, 'criterion': 'gini', 'min_samples_split': 0.3948714879875315, 'max_depth': 10}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:05,047] Trial 57 finished with value: 0.9984740590030519 and parameters: {'n_estimators': 250, 'criterion': 'entropy', 'min_samples_split': 0.28958439967950067, 'max_depth': 6}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:05,204] Trial 58 finished with value: 0.9811800610376399 and parameters: {'n_estimators': 75, 'criterion': 'entropy', 'min_samples_split': 0.42941245483987545, 'max_depth': 2}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:05,652] Trial 59 finished with value: 1.0 and parameters: {'n_estimators': 225, 'criterion': 'gini', 'min_samples_split': 0.20169834820887708, 'max_depth': 4}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:05,945] Trial 60 finished with value: 0.984231943031536 and parameters: {'n_estimators': 150, 'criterion': 'log_loss', 'min_samples_split': 0.6269306918813692, 'max_depth': 10}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:06,517] Trial 61 finished with value: 1.0 and parameters: {'n_estimators': 250, 'criterion': 'entropy', 'min_samples_split': 0.22353493617303932, 'max_depth': 4}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:07,055] Trial 62 finished with value: 1.0 and parameters: {'n_estimators': 250, 'criterion': 'entropy', 'min_samples_split': 0.23130320260110207, 'max_depth': 4}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:07,500] Trial 63 finished with value: 1.0 and parameters: {'n_estimators': 225, 'criterion': 'entropy', 'min_samples_split': 0.26953813825665474, 'max_depth': 4}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:07,946] Trial 64 finished with value: 0.9989827060020346 and parameters: {'n_estimators': 250, 'criterion': 'entropy', 'min_samples_split': 0.3200866909391279, 'max_depth': 2}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:08,064] Trial 65 finished with value: 1.0 and parameters: {'n_estimators': 50, 'criterion': 'entropy', 'min_samples_split': 0.23164231859891354, 'max_depth': 4}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:08,475] Trial 66 finished with value: 1.0 and parameters: {'n_estimators': 200, 'criterion': 'entropy', 'min_samples_split': 0.20132845603201285, 'max_depth': 4}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:08,910] Trial 67 finished with value: 0.9847405900305188 and parameters: {'n_estimators': 250, 'criterion': 'entropy', 'min_samples_split': 0.5532500463173666, 'max_depth': 6}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:09,302] Trial 68 finished with value: 0.9928789420142421 and parameters: {'n_estimators': 225, 'criterion': 'gini', 'min_samples_split': 0.35657571794917864, 'max_depth': 10}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:09,796] Trial 69 finished with value: 1.0 and parameters: {'n_estimators': 250, 'criterion': 'entropy', 'min_samples_split': 0.2706660747086987, 'max_depth': 8}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:10,089] Trial 70 finished with value: 0.9989827060020346 and parameters: {'n_estimators': 125, 'criterion': 'entropy', 'min_samples_split': 0.30753592767920535, 'max_depth': 10}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:10,557] Trial 71 finished with value: 0.9989827060020346 and parameters: {'n_estimators': 225, 'criterion': 'entropy', 'min_samples_split': 0.2541138041340079, 'max_depth': 4}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:11,015] Trial 72 finished with value: 1.0 and parameters: {'n_estimators': 225, 'criterion': 'entropy', 'min_samples_split': 0.2250231823002759, 'max_depth': 4}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:11,378] Trial 73 finished with value: 0.9928789420142421 and parameters: {'n_estimators': 200, 'criterion': 'entropy', 'min_samples_split': 0.32807416473302176, 'max_depth': 4}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:11,894] Trial 74 finished with value: 0.9979654120040692 and parameters: {'n_estimators': 250, 'criterion': 'entropy', 'min_samples_split': 0.28438896088175114, 'max_depth': 6}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:12,179] Trial 75 finished with value: 0.5 and parameters: {'n_estimators': 175, 'criterion': 'log_loss', 'min_samples_split': 0.9989179929260352, 'max_depth': 2}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:12,632] Trial 76 finished with value: 1.0 and parameters: {'n_estimators': 225, 'criterion': 'entropy', 'min_samples_split': 0.2527401117163879, 'max_depth': 4}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:12,861] Trial 77 finished with value: 0.9994913530010172 and parameters: {'n_estimators': 100, 'criterion': 'gini', 'min_samples_split': 0.2196407765080473, 'max_depth': 10}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:13,395] Trial 78 finished with value: 0.9994913530010172 and parameters: {'n_estimators': 250, 'criterion': 'entropy', 'min_samples_split': 0.24547891262817587, 'max_depth': 4}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:13,789] Trial 79 finished with value: 0.996439471007121 and parameters: {'n_estimators': 200, 'criterion': 'entropy', 'min_samples_split': 0.3851956337441472, 'max_depth': 10}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:13,906] Trial 80 finished with value: 0.9933943089430894 and parameters: {'n_estimators': 50, 'criterion': 'gini', 'min_samples_split': 0.2773547728423505, 'max_depth': 6}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:14,387] Trial 81 finished with value: 1.0 and parameters: {'n_estimators': 250, 'criterion': 'entropy', 'min_samples_split': 0.31280636946482276, 'max_depth': 2}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:14,862] Trial 82 finished with value: 1.0 and parameters: {'n_estimators': 250, 'criterion': 'entropy', 'min_samples_split': 0.34589577323607934, 'max_depth': 2}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:15,363] Trial 83 finished with value: 0.9974567650050865 and parameters: {'n_estimators': 225, 'criterion': 'entropy', 'min_samples_split': 0.2934969702309523, 'max_depth': 2}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:15,937] Trial 84 finished with value: 0.9974567650050865 and parameters: {'n_estimators': 250, 'criterion': 'entropy', 'min_samples_split': 0.26041534785781534, 'max_depth': 2}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:16,483] Trial 85 finished with value: 1.0 and parameters: {'n_estimators': 250, 'criterion': 'entropy', 'min_samples_split': 0.22365408872151096, 'max_depth': 4}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:16,601] Trial 86 finished with value: 0.5 and parameters: {'n_estimators': 75, 'criterion': 'entropy', 'min_samples_split': 0.8985118041392897, 'max_depth': 10}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:16,997] Trial 87 finished with value: 0.9918616480162767 and parameters: {'n_estimators': 225, 'criterion': 'gini', 'min_samples_split': 0.3654178887321058, 'max_depth': 4}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:17,584] Trial 88 finished with value: 1.0 and parameters: {'n_estimators': 250, 'criterion': 'log_loss', 'min_samples_split': 0.23850621778671105, 'max_depth': 10}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:17,703] Trial 89 finished with value: 0.9898270600203458 and parameters: {'n_estimators': 50, 'criterion': 'entropy', 'min_samples_split': 0.30439399091403363, 'max_depth': 8}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:17,921] Trial 90 finished with value: 1.0 and parameters: {'n_estimators': 125, 'criterion': 'gini', 'min_samples_split': 0.3297876814358223, 'max_depth': 6}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:18,349] Trial 91 finished with value: 1.0 and parameters: {'n_estimators': 225, 'criterion': 'gini', 'min_samples_split': 0.21464826690467897, 'max_depth': 6}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:18,799] Trial 92 finished with value: 1.0 and parameters: {'n_estimators': 225, 'criterion': 'gini', 'min_samples_split': 0.20566420317575837, 'max_depth': 6}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:19,217] Trial 93 finished with value: 1.0 and parameters: {'n_estimators': 200, 'criterion': 'gini', 'min_samples_split': 0.2714395974913563, 'max_depth': 4}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:19,583] Trial 94 finished with value: 0.5 and parameters: {'n_estimators': 250, 'criterion': 'gini', 'min_samples_split': 0.6883135949263472, 'max_depth': 8}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:20,122] Trial 95 finished with value: 1.0 and parameters: {'n_estimators': 250, 'criterion': 'entropy', 'min_samples_split': 0.24087807852856755, 'max_depth': 10}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:20,587] Trial 96 finished with value: 1.0 and parameters: {'n_estimators': 225, 'criterion': 'gini', 'min_samples_split': 0.2003438586315227, 'max_depth': 4}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:21,094] Trial 97 finished with value: 0.994913530010173 and parameters: {'n_estimators': 250, 'criterion': 'entropy', 'min_samples_split': 0.2620781468718766, 'max_depth': 10}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:21,643] Trial 98 finished with value: 1.0 and parameters: {'n_estimators': 225, 'criterion': 'entropy', 'min_samples_split': 0.28349127909683425, 'max_depth': 4}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:22,034] Trial 99 finished with value: 0.9994913530010172 and parameters: {'n_estimators': 200, 'criterion': 'gini', 'min_samples_split': 0.2378383849417578, 'max_depth': 10}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:22,158] Trial 100 finished with value: 0.9994913530010172 and parameters: {'n_estimators': 50, 'criterion': 'entropy', 'min_samples_split': 0.21836170076571376, 'max_depth': 8}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:22,521] Trial 101 finished with value: 1.0 and parameters: {'n_estimators': 175, 'criterion': 'log_loss', 'min_samples_split': 0.3211679586193072, 'max_depth': 4}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:22,959] Trial 102 finished with value: 0.9969481180061037 and parameters: {'n_estimators': 225, 'criterion': 'log_loss', 'min_samples_split': 0.29694855039527246, 'max_depth': 4}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:23,331] Trial 103 finished with value: 1.0 and parameters: {'n_estimators': 200, 'criterion': 'log_loss', 'min_samples_split': 0.354328703949019, 'max_depth': 4}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:23,909] Trial 104 finished with value: 1.0 and parameters: {'n_estimators': 250, 'criterion': 'log_loss', 'min_samples_split': 0.24771945970814307, 'max_depth': 4}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:24,199] Trial 105 finished with value: 0.9760935910478128 and parameters: {'n_estimators': 150, 'criterion': 'entropy', 'min_samples_split': 0.49035697915344584, 'max_depth': 4}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:24,626] Trial 106 finished with value: 0.9883011190233978 and parameters: {'n_estimators': 225, 'criterion': 'log_loss', 'min_samples_split': 0.4201919794795899, 'max_depth': 2}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:25,122] Trial 107 finished with value: 1.0 and parameters: {'n_estimators': 225, 'criterion': 'entropy', 'min_samples_split': 0.26188201762113705, 'max_depth': 6}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:25,564] Trial 108 finished with value: 1.0 and parameters: {'n_estimators': 250, 'criterion': 'gini', 'min_samples_split': 0.3365290924817964, 'max_depth': 10}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:25,768] Trial 109 finished with value: 0.9959308240081384 and parameters: {'n_estimators': 100, 'criterion': 'entropy', 'min_samples_split': 0.3106980840162074, 'max_depth': 2}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:26,311] Trial 110 finished with value: 1.0 and parameters: {'n_estimators': 250, 'criterion': 'log_loss', 'min_samples_split': 0.28173258875710766, 'max_depth': 4}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:26,461] Trial 111 finished with value: 0.9018316461140197 and parameters: {'n_estimators': 75, 'criterion': 'gini', 'min_samples_split': 0.6480945110279147, 'max_depth': 10}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:26,660] Trial 112 finished with value: 0.5 and parameters: {'n_estimators': 125, 'criterion': 'gini', 'min_samples_split': 0.6635695401601838, 'max_depth': 8}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:26,851] Trial 113 finished with value: 0.9974567650050865 and parameters: {'n_estimators': 100, 'criterion': 'gini', 'min_samples_split': 0.5868839902456133, 'max_depth': 10}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:26,989] Trial 114 finished with value: 0.9745676500508647 and parameters: {'n_estimators': 50, 'criterion': 'gini', 'min_samples_split': 0.5987003570033682, 'max_depth': 8}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:27,262] Trial 115 finished with value: 0.5 and parameters: {'n_estimators': 175, 'criterion': 'entropy', 'min_samples_split': 0.765318159809959, 'max_depth': 10}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:27,379] Trial 116 finished with value: 0.991353001017294 and parameters: {'n_estimators': 50, 'criterion': 'gini', 'min_samples_split': 0.5668999902260676, 'max_depth': 6}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:27,608] Trial 117 finished with value: 0.5 and parameters: {'n_estimators': 150, 'criterion': 'entropy', 'min_samples_split': 0.7292241281974775, 'max_depth': 4}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:27,804] Trial 118 finished with value: 0.9989827060020346 and parameters: {'n_estimators': 75, 'criterion': 'entropy', 'min_samples_split': 0.2280474623901446, 'max_depth': 10}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:28,154] Trial 119 finished with value: 0.9821973550356053 and parameters: {'n_estimators': 225, 'criterion': 'gini', 'min_samples_split': 0.6274263784915327, 'max_depth': 10}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:28,536] Trial 120 finished with value: 0.9908443540183113 and parameters: {'n_estimators': 200, 'criterion': 'entropy', 'min_samples_split': 0.3768198552015387, 'max_depth': 4}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:29,073] Trial 121 finished with value: 1.0 and parameters: {'n_estimators': 250, 'criterion': 'entropy', 'min_samples_split': 0.21232711902977044, 'max_depth': 10}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:29,638] Trial 122 finished with value: 1.0 and parameters: {'n_estimators': 250, 'criterion': 'entropy', 'min_samples_split': 0.23028991582249142, 'max_depth': 10}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:30,152] Trial 123 finished with value: 1.0 and parameters: {'n_estimators': 250, 'criterion': 'entropy', 'min_samples_split': 0.2002524626609758, 'max_depth': 10}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:30,641] Trial 124 finished with value: 1.0 and parameters: {'n_estimators': 250, 'criterion': 'entropy', 'min_samples_split': 0.25370190526139075, 'max_depth': 10}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:31,166] Trial 125 finished with value: 1.0 and parameters: {'n_estimators': 250, 'criterion': 'entropy', 'min_samples_split': 0.21691020330567154, 'max_depth': 10}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:31,667] Trial 126 finished with value: 1.0 and parameters: {'n_estimators': 250, 'criterion': 'gini', 'min_samples_split': 0.2759593997774258, 'max_depth': 6}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:32,156] Trial 127 finished with value: 1.0 and parameters: {'n_estimators': 225, 'criterion': 'entropy', 'min_samples_split': 0.2386483271033513, 'max_depth': 4}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:32,642] Trial 128 finished with value: 0.9979654120040692 and parameters: {'n_estimators': 225, 'criterion': 'entropy', 'min_samples_split': 0.29656163291354043, 'max_depth': 8}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:33,171] Trial 129 finished with value: 1.0 and parameters: {'n_estimators': 250, 'criterion': 'gini', 'min_samples_split': 0.25443053565326307, 'max_depth': 10}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:33,630] Trial 130 finished with value: 1.0 and parameters: {'n_estimators': 200, 'criterion': 'log_loss', 'min_samples_split': 0.26712931897890885, 'max_depth': 4}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:34,213] Trial 131 finished with value: 1.0 and parameters: {'n_estimators': 250, 'criterion': 'entropy', 'min_samples_split': 0.21582492391963418, 'max_depth': 10}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:34,797] Trial 132 finished with value: 1.0 and parameters: {'n_estimators': 250, 'criterion': 'entropy', 'min_samples_split': 0.2315304107571864, 'max_depth': 10}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:35,346] Trial 133 finished with value: 1.0 and parameters: {'n_estimators': 250, 'criterion': 'entropy', 'min_samples_split': 0.21450382366317713, 'max_depth': 10}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:35,483] Trial 134 finished with value: 1.0 and parameters: {'n_estimators': 50, 'criterion': 'entropy', 'min_samples_split': 0.24212506622573474, 'max_depth': 10}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:35,858] Trial 135 finished with value: 1.0 and parameters: {'n_estimators': 175, 'criterion': 'entropy', 'min_samples_split': 0.20204575098885513, 'max_depth': 10}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:36,350] Trial 136 finished with value: 1.0 and parameters: {'n_estimators': 250, 'criterion': 'entropy', 'min_samples_split': 0.316014818496542, 'max_depth': 4}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:36,538] Trial 137 finished with value: 0.9969481180061037 and parameters: {'n_estimators': 100, 'criterion': 'gini', 'min_samples_split': 0.28654693155956323, 'max_depth': 2}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:37,008] Trial 138 finished with value: 1.0 and parameters: {'n_estimators': 225, 'criterion': 'entropy', 'min_samples_split': 0.2562463931063602, 'max_depth': 10}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:37,473] Trial 139 finished with value: 0.9994913530010172 and parameters: {'n_estimators': 250, 'criterion': 'entropy', 'min_samples_split': 0.34690730324523184, 'max_depth': 10}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:37,728] Trial 140 finished with value: 0.994913530010173 and parameters: {'n_estimators': 125, 'criterion': 'gini', 'min_samples_split': 0.23028791942389595, 'max_depth': 4}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:38,205] Trial 141 finished with value: 0.9918616480162767 and parameters: {'n_estimators': 225, 'criterion': 'entropy', 'min_samples_split': 0.2740314040847944, 'max_depth': 10}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:38,630] Trial 142 finished with value: 0.9933875890132249 and parameters: {'n_estimators': 225, 'criterion': 'entropy', 'min_samples_split': 0.3255638476448347, 'max_depth': 10}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:39,109] Trial 143 finished with value: 1.0 and parameters: {'n_estimators': 250, 'criterion': 'entropy', 'min_samples_split': 0.29912083882507445, 'max_depth': 10}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:39,609] Trial 144 finished with value: 1.0 and parameters: {'n_estimators': 225, 'criterion': 'entropy', 'min_samples_split': 0.24726066416173134, 'max_depth': 10}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:40,065] Trial 145 finished with value: 1.0 and parameters: {'n_estimators': 200, 'criterion': 'log_loss', 'min_samples_split': 0.2231527899119495, 'max_depth': 10}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:40,594] Trial 146 finished with value: 1.0 and parameters: {'n_estimators': 225, 'criterion': 'entropy', 'min_samples_split': 0.2696081014796718, 'max_depth': 4}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:40,755] Trial 147 finished with value: 0.9689725330620549 and parameters: {'n_estimators': 75, 'criterion': 'entropy', 'min_samples_split': 0.5356771262671864, 'max_depth': 8}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:41,272] Trial 148 finished with value: 1.0 and parameters: {'n_estimators': 250, 'criterion': 'gini', 'min_samples_split': 0.2031269193936395, 'max_depth': 6}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:41,689] Trial 149 finished with value: 0.9877924720244151 and parameters: {'n_estimators': 225, 'criterion': 'entropy', 'min_samples_split': 0.6209459620781501, 'max_depth': 10}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:41,935] Trial 150 finished with value: 0.5 and parameters: {'n_estimators': 150, 'criterion': 'entropy', 'min_samples_split': 0.6719113651025206, 'max_depth': 4}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:42,430] Trial 151 finished with value: 1.0 and parameters: {'n_estimators': 225, 'criterion': 'gini', 'min_samples_split': 0.25854333683013336, 'max_depth': 8}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:42,845] Trial 152 finished with value: 0.9979654120040692 and parameters: {'n_estimators': 225, 'criterion': 'gini', 'min_samples_split': 0.28852470261636054, 'max_depth': 6}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:43,348] Trial 153 finished with value: 1.0 and parameters: {'n_estimators': 250, 'criterion': 'gini', 'min_samples_split': 0.22630281794422086, 'max_depth': 8}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:43,457] Trial 154 finished with value: 0.5 and parameters: {'n_estimators': 50, 'criterion': 'gini', 'min_samples_split': 0.8620693931774274, 'max_depth': 10}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:43,930] Trial 155 finished with value: 0.9994913530010172 and parameters: {'n_estimators': 250, 'criterion': 'gini', 'min_samples_split': 0.2413649402613675, 'max_depth': 10}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:44,342] Trial 156 finished with value: 0.9933875890132249 and parameters: {'n_estimators': 200, 'criterion': 'entropy', 'min_samples_split': 0.31081498737889224, 'max_depth': 8}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:44,788] Trial 157 finished with value: 1.0 and parameters: {'n_estimators': 225, 'criterion': 'log_loss', 'min_samples_split': 0.3322121810199141, 'max_depth': 4}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:45,191] Trial 158 finished with value: 1.0 and parameters: {'n_estimators': 225, 'criterion': 'gini', 'min_samples_split': 0.26282715980500915, 'max_depth': 2}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:45,714] Trial 159 finished with value: 1.0 and parameters: {'n_estimators': 250, 'criterion': 'entropy', 'min_samples_split': 0.21415295767336925, 'max_depth': 10}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:46,172] Trial 160 finished with value: 0.9771108850457783 and parameters: {'n_estimators': 250, 'criterion': 'gini', 'min_samples_split': 0.39638712135837084, 'max_depth': 4}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:46,346] Trial 161 finished with value: 1.0 and parameters: {'n_estimators': 75, 'criterion': 'entropy', 'min_samples_split': 0.35756836499430045, 'max_depth': 10}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:46,485] Trial 162 finished with value: 0.9994913530010172 and parameters: {'n_estimators': 50, 'criterion': 'entropy', 'min_samples_split': 0.3424658271400036, 'max_depth': 10}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:46,648] Trial 163 finished with value: 0.9888097660223805 and parameters: {'n_estimators': 75, 'criterion': 'entropy', 'min_samples_split': 0.3000025016156118, 'max_depth': 10}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:46,871] Trial 164 finished with value: 1.0 and parameters: {'n_estimators': 100, 'criterion': 'entropy', 'min_samples_split': 0.24185514195447877, 'max_depth': 10}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:47,333] Trial 165 finished with value: 0.9979654120040692 and parameters: {'n_estimators': 225, 'criterion': 'entropy', 'min_samples_split': 0.28233659120634963, 'max_depth': 10}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:47,448] Trial 166 finished with value: 0.9837232960325535 and parameters: {'n_estimators': 50, 'criterion': 'entropy', 'min_samples_split': 0.32173531234286645, 'max_depth': 10}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:47,568] Trial 167 finished with value: 0.9918616480162767 and parameters: {'n_estimators': 50, 'criterion': 'entropy', 'min_samples_split': 0.36843155535501104, 'max_depth': 4}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:48,036] Trial 168 finished with value: 1.0 and parameters: {'n_estimators': 250, 'criterion': 'gini', 'min_samples_split': 0.22423348721410674, 'max_depth': 6}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:48,256] Trial 169 finished with value: 0.9928789420142421 and parameters: {'n_estimators': 100, 'criterion': 'entropy', 'min_samples_split': 0.20231155566699482, 'max_depth': 10}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:48,424] Trial 170 finished with value: 0.9877924720244151 and parameters: {'n_estimators': 75, 'criterion': 'log_loss', 'min_samples_split': 0.4386013953852535, 'max_depth': 10}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:48,597] Trial 171 finished with value: 1.0 and parameters: {'n_estimators': 75, 'criterion': 'entropy', 'min_samples_split': 0.21601161418344483, 'max_depth': 10}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:48,862] Trial 172 finished with value: 1.0 and parameters: {'n_estimators': 125, 'criterion': 'entropy', 'min_samples_split': 0.2365133294794888, 'max_depth': 10}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:49,090] Trial 173 finished with value: 1.0 and parameters: {'n_estimators': 100, 'criterion': 'entropy', 'min_samples_split': 0.20084608951195018, 'max_depth': 10}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:49,606] Trial 174 finished with value: 0.9994913530010172 and parameters: {'n_estimators': 250, 'criterion': 'entropy', 'min_samples_split': 0.2565037603725496, 'max_depth': 10}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:50,621] Trial 175 finished with value: 0.9954221770091556 and parameters: {'n_estimators': 125, 'criterion': 'entropy', 'min_samples_split': 0.27198762433501805, 'max_depth': 4}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:52,937] Trial 176 finished with value: 1.0 and parameters: {'n_estimators': 225, 'criterion': 'entropy', 'min_samples_split': 0.23288973601890575, 'max_depth': 10}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:53,146] Trial 177 finished with value: 1.0 and parameters: {'n_estimators': 100, 'criterion': 'gini', 'min_samples_split': 0.24825828024193933, 'max_depth': 10}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:53,674] Trial 178 finished with value: 1.0 and parameters: {'n_estimators': 250, 'criterion': 'entropy', 'min_samples_split': 0.21840571074409246, 'max_depth': 10}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:53,805] Trial 179 finished with value: 0.9994913530010172 and parameters: {'n_estimators': 50, 'criterion': 'entropy', 'min_samples_split': 0.2926235365546154, 'max_depth': 4}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:54,189] Trial 180 finished with value: 0.7187182095625636 and parameters: {'n_estimators': 250, 'criterion': 'gini', 'min_samples_split': 0.6468097536400981, 'max_depth': 8}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:54,315] Trial 181 finished with value: 0.9989827060020346 and parameters: {'n_estimators': 50, 'criterion': 'entropy', 'min_samples_split': 0.2346009918559545, 'max_depth': 6}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:54,465] Trial 182 finished with value: 1.0 and parameters: {'n_estimators': 50, 'criterion': 'entropy', 'min_samples_split': 0.21366868899468244, 'max_depth': 6}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:54,604] Trial 183 finished with value: 1.0 and parameters: {'n_estimators': 50, 'criterion': 'entropy', 'min_samples_split': 0.2503060102694169, 'max_depth': 6}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:54,716] Trial 184 finished with value: 0.9898270600203458 and parameters: {'n_estimators': 50, 'criterion': 'entropy', 'min_samples_split': 0.3107592408296583, 'max_depth': 10}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:54,899] Trial 185 finished with value: 0.9923702950152594 and parameters: {'n_estimators': 75, 'criterion': 'entropy', 'min_samples_split': 0.26993133365040395, 'max_depth': 6}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:55,224] Trial 186 finished with value: 1.0 and parameters: {'n_estimators': 150, 'criterion': 'entropy', 'min_samples_split': 0.22503304380733458, 'max_depth': 6}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:55,551] Trial 187 finished with value: 0.9994913530010172 and parameters: {'n_estimators': 175, 'criterion': 'log_loss', 'min_samples_split': 0.3332825938114944, 'max_depth': 4}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:55,989] Trial 188 finished with value: 0.991353001017294 and parameters: {'n_estimators': 225, 'criterion': 'gini', 'min_samples_split': 0.24317570191530893, 'max_depth': 2}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:56,494] Trial 189 finished with value: 1.0 and parameters: {'n_estimators': 250, 'criterion': 'entropy', 'min_samples_split': 0.21256705995228742, 'max_depth': 6}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:56,611] Trial 190 finished with value: 0.9923702950152594 and parameters: {'n_estimators': 50, 'criterion': 'entropy', 'min_samples_split': 0.2819003227427971, 'max_depth': 10}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:57,041] Trial 191 finished with value: 0.9994913530010172 and parameters: {'n_estimators': 225, 'criterion': 'gini', 'min_samples_split': 0.25854716586795373, 'max_depth': 8}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:57,242] Trial 192 finished with value: 1.0 and parameters: {'n_estimators': 100, 'criterion': 'gini', 'min_samples_split': 0.20211611594492038, 'max_depth': 8}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:57,501] Trial 193 finished with value: 1.0 and parameters: {'n_estimators': 125, 'criterion': 'gini', 'min_samples_split': 0.22981939631567122, 'max_depth': 8}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:57,747] Trial 194 finished with value: 0.9984740590030519 and parameters: {'n_estimators': 100, 'criterion': 'gini', 'min_samples_split': 0.2492012690064685, 'max_depth': 4}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:58,039] Trial 195 finished with value: 1.0 and parameters: {'n_estimators': 125, 'criterion': 'gini', 'min_samples_split': 0.22982853271708084, 'max_depth': 8}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:58,550] Trial 196 finished with value: 1.0 and parameters: {'n_estimators': 250, 'criterion': 'entropy', 'min_samples_split': 0.30171005283024277, 'max_depth': 8}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:58,712] Trial 197 finished with value: 1.0 and parameters: {'n_estimators': 75, 'criterion': 'gini', 'min_samples_split': 0.2653776947831852, 'max_depth': 10}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:59,236] Trial 198 finished with value: 1.0 and parameters: {'n_estimators': 250, 'criterion': 'entropy', 'min_samples_split': 0.21411796617225917, 'max_depth': 10}. Best is trial 1 with value: 1.0.\n",
      "[I 2025-03-29 17:39:59,792] Trial 199 finished with value: 1.0 and parameters: {'n_estimators': 225, 'criterion': 'entropy', 'min_samples_split': 0.279532567249055, 'max_depth': 6}. Best is trial 1 with value: 1.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['n_estimators', 'criterion', 'min_samples_split', 'max_depth'] RandomForestClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 17:40:04,084] A new study created in memory with name: no-name-6a817e2e-8af4-4012-84de-dd5632adc1db\n",
      "[I 2025-03-29 17:40:04,104] Trial 0 finished with value: 0.5 and parameters: {'loss': 'exponential', 'n_estimators': 7, 'learning_rate': 0.016558024024563484, 'subsample': 0.8589458873864946, 'min_samples_leaf': 0.6177183081856287, 'min_samples_split': 0.5093791289947401}. Best is trial 0 with value: 0.5.\n",
      "[I 2025-03-29 17:40:04,123] Trial 1 finished with value: 0.5 and parameters: {'loss': 'log_loss', 'n_estimators': 3, 'learning_rate': 0.04193546674704217, 'subsample': 0.41918971026185925, 'min_samples_leaf': 0.31442363034499127, 'min_samples_split': 0.7250552205882812}. Best is trial 0 with value: 0.5.\n",
      "[I 2025-03-29 17:40:04,142] Trial 2 finished with value: 0.5 and parameters: {'loss': 'exponential', 'n_estimators': 7, 'learning_rate': 0.0016992911670141529, 'subsample': 0.32371664900191505, 'min_samples_leaf': 0.42904543369199755, 'min_samples_split': 0.6657890403246457}. Best is trial 0 with value: 0.5.\n",
      "[I 2025-03-29 17:40:04,162] Trial 3 finished with value: 0.5 and parameters: {'loss': 'log_loss', 'n_estimators': 7, 'learning_rate': 0.0012855014167013788, 'subsample': 0.5867394812662791, 'min_samples_leaf': 0.34070049685820936, 'min_samples_split': 0.4207544607261958}. Best is trial 0 with value: 0.5.\n",
      "[I 2025-03-29 17:40:04,179] Trial 4 finished with value: 0.5 and parameters: {'loss': 'exponential', 'n_estimators': 5, 'learning_rate': 0.007958843824887448, 'subsample': 0.6663169397991187, 'min_samples_leaf': 0.4623256484449603, 'min_samples_split': 0.691510774050913}. Best is trial 0 with value: 0.5.\n",
      "[I 2025-03-29 17:40:04,202] Trial 5 finished with value: 0.5 and parameters: {'loss': 'exponential', 'n_estimators': 6, 'learning_rate': 0.024115206764597066, 'subsample': 0.48639266107825346, 'min_samples_leaf': 0.7415848070158206, 'min_samples_split': 0.4287454625377049}. Best is trial 0 with value: 0.5.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run learned-bee-80 at: http://127.0.0.1:1500/#/experiments/1/runs/77793f7212be4d79af179a4b9ec9dae4\n",
      "🧪 View experiment at: http://127.0.0.1:1500/#/experiments/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 17:40:04,277] Trial 6 finished with value: 0.5 and parameters: {'loss': 'log_loss', 'n_estimators': 7, 'learning_rate': 0.03650607400588124, 'subsample': 0.6096155518434742, 'min_samples_leaf': 0.44238400516030973, 'min_samples_split': 0.5962923939873284}. Best is trial 0 with value: 0.5.\n",
      "[I 2025-03-29 17:40:04,309] Trial 7 finished with value: 0.5 and parameters: {'loss': 'log_loss', 'n_estimators': 4, 'learning_rate': 0.03683116503850484, 'subsample': 0.5710256741226782, 'min_samples_leaf': 0.46457446346215603, 'min_samples_split': 0.4135508741440024}. Best is trial 0 with value: 0.5.\n",
      "[I 2025-03-29 17:40:04,338] Trial 8 finished with value: 0.5 and parameters: {'loss': 'log_loss', 'n_estimators': 8, 'learning_rate': 0.001928308082463014, 'subsample': 0.5960675523853807, 'min_samples_leaf': 0.4659385185353116, 'min_samples_split': 0.6081892532978234}. Best is trial 0 with value: 0.5.\n",
      "[I 2025-03-29 17:40:04,360] Trial 9 finished with value: 0.5 and parameters: {'loss': 'exponential', 'n_estimators': 5, 'learning_rate': 0.04565577811791707, 'subsample': 0.5942191433836098, 'min_samples_leaf': 0.6632468817197185, 'min_samples_split': 0.3534176461518924}. Best is trial 0 with value: 0.5.\n",
      "[I 2025-03-29 17:40:04,415] Trial 10 finished with value: 0.5 and parameters: {'loss': 'exponential', 'n_estimators': 8, 'learning_rate': 0.00913556711151816, 'subsample': 0.8693040402346989, 'min_samples_leaf': 0.8540188925060476, 'min_samples_split': 0.30641375769988527}. Best is trial 0 with value: 0.5.\n",
      "[I 2025-03-29 17:40:04,459] Trial 11 finished with value: 0.5 and parameters: {'loss': 'log_loss', 'n_estimators': 3, 'learning_rate': 0.015805818133532604, 'subsample': 0.40197542814848675, 'min_samples_leaf': 0.30371282119154663, 'min_samples_split': 0.8869232322047734}. Best is trial 0 with value: 0.5.\n",
      "[I 2025-03-29 17:40:04,499] Trial 12 finished with value: 0.5 and parameters: {'loss': 'exponential', 'n_estimators': 3, 'learning_rate': 0.003595289328438132, 'subsample': 0.8282538986812465, 'min_samples_leaf': 0.5958644707310246, 'min_samples_split': 0.8935919437738197}. Best is trial 0 with value: 0.5.\n",
      "[I 2025-03-29 17:40:04,554] Trial 13 finished with value: 0.5 and parameters: {'loss': 'log_loss', 'n_estimators': 6, 'learning_rate': 0.012625999465890903, 'subsample': 0.42784350431032175, 'min_samples_leaf': 0.5865677777636126, 'min_samples_split': 0.5223423629134201}. Best is trial 0 with value: 0.5.\n",
      "[I 2025-03-29 17:40:04,597] Trial 14 finished with value: 0.5 and parameters: {'loss': 'exponential', 'n_estimators': 4, 'learning_rate': 0.004652038754635122, 'subsample': 0.35767475171807656, 'min_samples_leaf': 0.36785899441001446, 'min_samples_split': 0.7418458338178158}. Best is trial 0 with value: 0.5.\n",
      "[I 2025-03-29 17:40:04,646] Trial 15 finished with value: 0.5 and parameters: {'loss': 'log_loss', 'n_estimators': 4, 'learning_rate': 0.018533738286391016, 'subsample': 0.7166847277991831, 'min_samples_leaf': 0.5493487676994411, 'min_samples_split': 0.49868733977491747}. Best is trial 0 with value: 0.5.\n",
      "[I 2025-03-29 17:40:04,695] Trial 16 finished with value: 0.5 and parameters: {'loss': 'exponential', 'n_estimators': 6, 'learning_rate': 0.000690239346728853, 'subsample': 0.49335108738868466, 'min_samples_leaf': 0.7254684124375932, 'min_samples_split': 0.5132395911766362}. Best is trial 0 with value: 0.5.\n",
      "[I 2025-03-29 17:40:04,744] Trial 17 finished with value: 0.5 and parameters: {'loss': 'log_loss', 'n_estimators': 5, 'learning_rate': 0.020870406090305063, 'subsample': 0.4187488589827952, 'min_samples_leaf': 0.363806922907274, 'min_samples_split': 0.7750509076308469}. Best is trial 0 with value: 0.5.\n",
      "[I 2025-03-29 17:40:04,798] Trial 18 finished with value: 0.5 and parameters: {'loss': 'exponential', 'n_estimators': 7, 'learning_rate': 0.007855799271452593, 'subsample': 0.7520462411354517, 'min_samples_leaf': 0.5141700360503433, 'min_samples_split': 0.5718255150341922}. Best is trial 0 with value: 0.5.\n",
      "[I 2025-03-29 17:40:04,833] Trial 19 finished with value: 0.5 and parameters: {'loss': 'log_loss', 'n_estimators': 3, 'learning_rate': 0.02832217193956413, 'subsample': 0.30068710088587275, 'min_samples_leaf': 0.8853180054403444, 'min_samples_split': 0.45752911084866854}. Best is trial 0 with value: 0.5.\n",
      "[I 2025-03-29 17:40:04,886] Trial 20 finished with value: 0.5 and parameters: {'loss': 'log_loss', 'n_estimators': 8, 'learning_rate': 0.047818476916888016, 'subsample': 0.46110369438450516, 'min_samples_leaf': 0.3022955758076029, 'min_samples_split': 0.36098133213408695}. Best is trial 0 with value: 0.5.\n",
      "[I 2025-03-29 17:40:04,924] Trial 21 finished with value: 0.5 and parameters: {'loss': 'exponential', 'n_estimators': 7, 'learning_rate': 0.002319270312366552, 'subsample': 0.3327805176177615, 'min_samples_leaf': 0.4047215822130063, 'min_samples_split': 0.6979383555380465}. Best is trial 0 with value: 0.5.\n",
      "[I 2025-03-29 17:40:04,961] Trial 22 finished with value: 0.5 and parameters: {'loss': 'exponential', 'n_estimators': 7, 'learning_rate': 0.0006637996341069926, 'subsample': 0.3611031108987903, 'min_samples_leaf': 0.3973576009422616, 'min_samples_split': 0.6753877728477347}. Best is trial 0 with value: 0.5.\n",
      "[I 2025-03-29 17:40:05,012] Trial 23 finished with value: 0.5 and parameters: {'loss': 'exponential', 'n_estimators': 6, 'learning_rate': 0.001095070200628399, 'subsample': 0.3116758193386804, 'min_samples_leaf': 0.5091066279440188, 'min_samples_split': 0.8082170775639503}. Best is trial 0 with value: 0.5.\n",
      "[I 2025-03-29 17:40:05,052] Trial 24 finished with value: 0.5 and parameters: {'loss': 'exponential', 'n_estimators': 8, 'learning_rate': 0.00298635330087405, 'subsample': 0.3810970098845238, 'min_samples_leaf': 0.6372367837403536, 'min_samples_split': 0.6538131197893373}. Best is trial 0 with value: 0.5.\n",
      "[I 2025-03-29 17:40:05,097] Trial 25 finished with value: 0.5 and parameters: {'loss': 'exponential', 'n_estimators': 7, 'learning_rate': 0.0052807157787427, 'subsample': 0.33487674326004624, 'min_samples_leaf': 0.3285775061085497, 'min_samples_split': 0.5587816880858174}. Best is trial 0 with value: 0.5.\n",
      "[I 2025-03-29 17:40:05,135] Trial 26 finished with value: 0.5 and parameters: {'loss': 'exponential', 'n_estimators': 6, 'learning_rate': 0.011593773744305168, 'subsample': 0.5220535750958204, 'min_samples_leaf': 0.41421751496946985, 'min_samples_split': 0.6519211870294355}. Best is trial 0 with value: 0.5.\n",
      "[I 2025-03-29 17:40:05,178] Trial 27 finished with value: 0.5 and parameters: {'loss': 'exponential', 'n_estimators': 5, 'learning_rate': 0.005761332480569463, 'subsample': 0.44625765312951077, 'min_samples_leaf': 0.7322090345612493, 'min_samples_split': 0.8011629109712306}. Best is trial 0 with value: 0.5.\n",
      "[I 2025-03-29 17:40:05,226] Trial 28 finished with value: 0.5 and parameters: {'loss': 'log_loss', 'n_estimators': 4, 'learning_rate': 0.0011874022009712253, 'subsample': 0.5315937097534266, 'min_samples_leaf': 0.5638764057070581, 'min_samples_split': 0.7357627915804748}. Best is trial 0 with value: 0.5.\n",
      "[I 2025-03-29 17:40:05,279] Trial 29 finished with value: 0.5 and parameters: {'loss': 'log_loss', 'n_estimators': 8, 'learning_rate': 0.03318239507174296, 'subsample': 0.3878854396297631, 'min_samples_leaf': 0.3485549047880292, 'min_samples_split': 0.470921562322371}. Best is trial 0 with value: 0.5.\n",
      "[I 2025-03-29 17:40:05,317] Trial 30 finished with value: 0.5 and parameters: {'loss': 'exponential', 'n_estimators': 7, 'learning_rate': 0.0017012255442190726, 'subsample': 0.3298546662561904, 'min_samples_leaf': 0.3263128226264287, 'min_samples_split': 0.6231451041875927}. Best is trial 0 with value: 0.5.\n",
      "[I 2025-03-29 17:40:05,364] Trial 31 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 7, 'learning_rate': 0.0010990929364957356, 'subsample': 0.6734407710629992, 'min_samples_leaf': 0.3305721213423569, 'min_samples_split': 0.39629459893430935}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:05,413] Trial 32 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 7, 'learning_rate': 0.0008576706321895392, 'subsample': 0.7918908465202735, 'min_samples_leaf': 0.3630530526695036, 'min_samples_split': 0.37902653141081044}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:05,455] Trial 33 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 6, 'learning_rate': 0.0009064116837775875, 'subsample': 0.7815296602781235, 'min_samples_leaf': 0.3823477494300363, 'min_samples_split': 0.37922055043745917}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:05,506] Trial 34 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 6, 'learning_rate': 0.0008820051037029327, 'subsample': 0.7970652229543336, 'min_samples_leaf': 0.39275438078620367, 'min_samples_split': 0.379270734417629}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:05,547] Trial 35 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 6, 'learning_rate': 0.0005073418049945587, 'subsample': 0.7971571261817296, 'min_samples_leaf': 0.378499251180722, 'min_samples_split': 0.37566544177762234}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:05,582] Trial 36 finished with value: 0.5 and parameters: {'loss': 'log_loss', 'n_estimators': 6, 'learning_rate': 0.000886881673554402, 'subsample': 0.673785283796284, 'min_samples_leaf': 0.34865843476772507, 'min_samples_split': 0.32427242737819445}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:05,628] Trial 37 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 6, 'learning_rate': 0.0008845655009930861, 'subsample': 0.8902787230784814, 'min_samples_leaf': 0.3831925983268038, 'min_samples_split': 0.3868901657442707}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:05,663] Trial 38 finished with value: 0.5 and parameters: {'loss': 'log_loss', 'n_estimators': 7, 'learning_rate': 0.0013715091520578207, 'subsample': 0.7696362942749165, 'min_samples_leaf': 0.43595949654808264, 'min_samples_split': 0.3312638557931405}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:05,712] Trial 39 finished with value: 0.8413812247227254 and parameters: {'loss': 'log_loss', 'n_estimators': 5, 'learning_rate': 0.0005345813880064527, 'subsample': 0.6668795455024599, 'min_samples_leaf': 0.3319921388060796, 'min_samples_split': 0.40015650141926384}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:05,767] Trial 40 finished with value: 0.8418888378863443 and parameters: {'loss': 'log_loss', 'n_estimators': 7, 'learning_rate': 0.000880586406571988, 'subsample': 0.7080751599201707, 'min_samples_leaf': 0.3536765803338657, 'min_samples_split': 0.44346979388729213}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:05,806] Trial 41 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 6, 'learning_rate': 0.0005012695336134392, 'subsample': 0.8152478451386438, 'min_samples_leaf': 0.38932982783942727, 'min_samples_split': 0.36202682012279386}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:05,859] Trial 42 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 6, 'learning_rate': 0.0006867406551040693, 'subsample': 0.7777499180230146, 'min_samples_leaf': 0.36908935576623525, 'min_samples_split': 0.385731413906494}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:05,904] Trial 43 finished with value: 0.5 and parameters: {'loss': 'log_loss', 'n_estimators': 7, 'learning_rate': 0.0014358008125413995, 'subsample': 0.8299054041331758, 'min_samples_leaf': 0.4213950793872008, 'min_samples_split': 0.33760657502135516}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:05,943] Trial 44 finished with value: 0.5 and parameters: {'loss': 'log_loss', 'n_estimators': 5, 'learning_rate': 0.0010239289383110564, 'subsample': 0.6260707105578694, 'min_samples_leaf': 0.47967847037387135, 'min_samples_split': 0.37962280144775185}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:06,002] Trial 45 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 6, 'learning_rate': 0.0006142460574207699, 'subsample': 0.724333076583357, 'min_samples_leaf': 0.31802630437246343, 'min_samples_split': 0.42017016066448537}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:06,053] Trial 46 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 6, 'learning_rate': 0.002127452991791382, 'subsample': 0.8226683923271353, 'min_samples_leaf': 0.374197281148643, 'min_samples_split': 0.3073745122184827}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:06,093] Trial 47 finished with value: 0.5 and parameters: {'loss': 'log_loss', 'n_estimators': 7, 'learning_rate': 0.0007700212833612002, 'subsample': 0.7887451692235702, 'min_samples_leaf': 0.4423872208424406, 'min_samples_split': 0.34605537658614954}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:06,136] Trial 48 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 5, 'learning_rate': 0.0015566890933557214, 'subsample': 0.8730433961734636, 'min_samples_leaf': 0.3387161534339578, 'min_samples_split': 0.36995013637375895}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:06,176] Trial 49 finished with value: 0.5 and parameters: {'loss': 'log_loss', 'n_estimators': 6, 'learning_rate': 0.0010803023485771628, 'subsample': 0.6993524554751256, 'min_samples_leaf': 0.39100943648855857, 'min_samples_split': 0.43921294450061976}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:06,227] Trial 50 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 8, 'learning_rate': 0.0008359479667258285, 'subsample': 0.7428929996298812, 'min_samples_leaf': 0.31240644223266845, 'min_samples_split': 0.4030017181096699}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:06,283] Trial 51 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 6, 'learning_rate': 0.0005748686815884806, 'subsample': 0.8798270500121781, 'min_samples_leaf': 0.38585574948398665, 'min_samples_split': 0.3928935077234923}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:06,336] Trial 52 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 6, 'learning_rate': 0.0008752171415756573, 'subsample': 0.8958449831500929, 'min_samples_leaf': 0.3793881668353028, 'min_samples_split': 0.4123056741584275}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:06,457] Trial 53 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 6, 'learning_rate': 0.000986968464825359, 'subsample': 0.8430782354177692, 'min_samples_leaf': 0.3584229707991322, 'min_samples_split': 0.3192932623074988}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:06,501] Trial 54 finished with value: 0.5 and parameters: {'loss': 'log_loss', 'n_estimators': 7, 'learning_rate': 0.0007384833937265392, 'subsample': 0.6382458796013546, 'min_samples_leaf': 0.4071117096806328, 'min_samples_split': 0.37252520219480467}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:06,551] Trial 55 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 5, 'learning_rate': 0.0012185718060074501, 'subsample': 0.788591939993571, 'min_samples_leaf': 0.3430587284857641, 'min_samples_split': 0.34792290563026473}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:06,597] Trial 56 finished with value: 0.5 and parameters: {'loss': 'log_loss', 'n_estimators': 7, 'learning_rate': 0.0026810223588806677, 'subsample': 0.7453881410145352, 'min_samples_leaf': 0.4528578058048801, 'min_samples_split': 0.48113937213571967}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:06,641] Trial 57 finished with value: 0.5 and parameters: {'loss': 'log_loss', 'n_estimators': 6, 'learning_rate': 0.0017481419226266076, 'subsample': 0.5557392410861268, 'min_samples_leaf': 0.4724614755694236, 'min_samples_split': 0.4294109960968843}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:06,677] Trial 58 finished with value: 0.5 and parameters: {'loss': 'log_loss', 'n_estimators': 6, 'learning_rate': 0.0005712129339646996, 'subsample': 0.8030555547180964, 'min_samples_leaf': 0.4199119256893534, 'min_samples_split': 0.39033186650908036}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:06,727] Trial 59 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 5, 'learning_rate': 0.0006590906738741468, 'subsample': 0.8569234693264027, 'min_samples_leaf': 0.31620046863564566, 'min_samples_split': 0.3545852955956996}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:06,777] Trial 60 finished with value: 0.5 and parameters: {'loss': 'log_loss', 'n_estimators': 7, 'learning_rate': 0.001384736269631863, 'subsample': 0.6827344703679961, 'min_samples_leaf': 0.37110902002465534, 'min_samples_split': 0.3648369022811208}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:06,826] Trial 61 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 6, 'learning_rate': 0.0005637905442488231, 'subsample': 0.8252710443602145, 'min_samples_leaf': 0.3900837931987048, 'min_samples_split': 0.38227872378653915}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:06,884] Trial 62 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 6, 'learning_rate': 0.0005213271787457744, 'subsample': 0.8969298164243329, 'min_samples_leaf': 0.4044437119968738, 'min_samples_split': 0.4083610331396583}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:06,939] Trial 63 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 6, 'learning_rate': 0.0007540527073066271, 'subsample': 0.8060426597461439, 'min_samples_leaf': 0.3608145021388795, 'min_samples_split': 0.33915243947956647}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:06,978] Trial 64 finished with value: 0.5 and parameters: {'loss': 'log_loss', 'n_estimators': 6, 'learning_rate': 0.0009727018501075842, 'subsample': 0.7564907561064922, 'min_samples_leaf': 0.49006797320230266, 'min_samples_split': 0.35876249501900537}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:07,038] Trial 65 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 7, 'learning_rate': 0.0005115613276186478, 'subsample': 0.8526613772233107, 'min_samples_leaf': 0.38318313084676703, 'min_samples_split': 0.45273011679943576}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:07,080] Trial 66 finished with value: 0.5 and parameters: {'loss': 'log_loss', 'n_estimators': 5, 'learning_rate': 0.0012348584563430308, 'subsample': 0.7363785684437196, 'min_samples_leaf': 0.4277709306755113, 'min_samples_split': 0.31406893258128005}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:07,123] Trial 67 finished with value: 0.5 and parameters: {'loss': 'log_loss', 'n_estimators': 7, 'learning_rate': 0.000795439365844867, 'subsample': 0.6459497732583253, 'min_samples_leaf': 0.3389113141677083, 'min_samples_split': 0.4298351795156679}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:07,166] Trial 68 finished with value: 0.5 and parameters: {'loss': 'log_loss', 'n_estimators': 6, 'learning_rate': 0.0009595842969802644, 'subsample': 0.7664715212823385, 'min_samples_leaf': 0.40082189877341456, 'min_samples_split': 0.37013377750479803}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:07,227] Trial 69 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 8, 'learning_rate': 0.0006263060082917134, 'subsample': 0.6987161114161364, 'min_samples_leaf': 0.3005359164943742, 'min_samples_split': 0.3330144018331653}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:07,272] Trial 70 finished with value: 0.5 and parameters: {'loss': 'log_loss', 'n_estimators': 7, 'learning_rate': 0.00363746298246442, 'subsample': 0.8099760707923386, 'min_samples_leaf': 0.7771676001484998, 'min_samples_split': 0.39510122426400407}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:07,337] Trial 71 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 6, 'learning_rate': 0.0007011232312102719, 'subsample': 0.7815647888373861, 'min_samples_leaf': 0.36529417094986355, 'min_samples_split': 0.3777652851144455}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:07,386] Trial 72 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 6, 'learning_rate': 0.0006726620218148522, 'subsample': 0.7735812808935395, 'min_samples_leaf': 0.37591779624563904, 'min_samples_split': 0.39060343508898493}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:07,437] Trial 73 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 6, 'learning_rate': 0.0008018961226443264, 'subsample': 0.8470313133049996, 'min_samples_leaf': 0.35393064198032675, 'min_samples_split': 0.3582135108789822}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:07,486] Trial 74 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 6, 'learning_rate': 0.0010783565366228865, 'subsample': 0.7209000181284456, 'min_samples_leaf': 0.32711008557565485, 'min_samples_split': 0.3861891097494934}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:07,529] Trial 75 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 5, 'learning_rate': 0.0005064799946326538, 'subsample': 0.802753186683969, 'min_samples_leaf': 0.3664152162615681, 'min_samples_split': 0.41363761971752144}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:07,593] Trial 76 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 6, 'learning_rate': 0.0006858822436099961, 'subsample': 0.8596431038183276, 'min_samples_leaf': 0.39627647200344457, 'min_samples_split': 0.3003798787694542}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:07,679] Trial 77 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 7, 'learning_rate': 0.0006122573370443133, 'subsample': 0.8257710488101909, 'min_samples_leaf': 0.3485883960493631, 'min_samples_split': 0.34573591941013204}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:07,768] Trial 78 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 6, 'learning_rate': 0.001188049881402037, 'subsample': 0.756309805495155, 'min_samples_leaf': 0.3334820173624484, 'min_samples_split': 0.37675030222113387}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:07,855] Trial 79 finished with value: 0.5 and parameters: {'loss': 'log_loss', 'n_estimators': 4, 'learning_rate': 0.0009188323068295538, 'subsample': 0.609432704902084, 'min_samples_leaf': 0.4166209591566042, 'min_samples_split': 0.42446807272468023}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:07,923] Trial 80 finished with value: 0.5 and parameters: {'loss': 'log_loss', 'n_estimators': 6, 'learning_rate': 0.0008292497331753336, 'subsample': 0.7305205956265131, 'min_samples_leaf': 0.44269504903116474, 'min_samples_split': 0.36346738142988416}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:07,979] Trial 81 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 6, 'learning_rate': 0.0005721177084199104, 'subsample': 0.6878937524530128, 'min_samples_leaf': 0.3113488945144565, 'min_samples_split': 0.4033928795756549}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:08,034] Trial 82 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 6, 'learning_rate': 0.0006104182126002518, 'subsample': 0.7242051005894083, 'min_samples_leaf': 0.32224134043790437, 'min_samples_split': 0.41713745384788936}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:08,086] Trial 83 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 6, 'learning_rate': 0.0006965031288403796, 'subsample': 0.7972609098140054, 'min_samples_leaf': 0.37831761977532186, 'min_samples_split': 0.5355898902968529}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:08,150] Trial 84 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 7, 'learning_rate': 0.0007469420666933966, 'subsample': 0.8766538420833943, 'min_samples_leaf': 0.3206675770246147, 'min_samples_split': 0.40121118721440147}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:08,194] Trial 85 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 5, 'learning_rate': 0.0011192076337646385, 'subsample': 0.7764059886901141, 'min_samples_leaf': 0.342845748775035, 'min_samples_split': 0.3502786574587867}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:08,248] Trial 86 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 6, 'learning_rate': 0.0014870145494609761, 'subsample': 0.8342562052592136, 'min_samples_leaf': 0.3594422051271412, 'min_samples_split': 0.4402593010087228}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:08,293] Trial 87 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 6, 'learning_rate': 0.0006321378872561751, 'subsample': 0.7449523249001754, 'min_samples_leaf': 0.308590728996022, 'min_samples_split': 0.32487551607979503}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:08,335] Trial 88 finished with value: 0.5 and parameters: {'loss': 'exponential', 'n_estimators': 7, 'learning_rate': 0.000892036387082344, 'subsample': 0.7123713930324945, 'min_samples_leaf': 0.3868194519885451, 'min_samples_split': 0.3849389608549755}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:08,377] Trial 89 finished with value: 0.5 and parameters: {'loss': 'log_loss', 'n_estimators': 5, 'learning_rate': 0.006744198115738371, 'subsample': 0.649491618383195, 'min_samples_leaf': 0.4086812944502291, 'min_samples_split': 0.3700520105827011}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:08,430] Trial 90 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 6, 'learning_rate': 0.0005060687674161211, 'subsample': 0.81103881001485, 'min_samples_leaf': 0.37254635519023405, 'min_samples_split': 0.34367031058091746}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:08,484] Trial 91 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 6, 'learning_rate': 0.0024019001689866795, 'subsample': 0.8222293832836131, 'min_samples_leaf': 0.3948791116533385, 'min_samples_split': 0.3126629451160575}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:08,526] Trial 92 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 6, 'learning_rate': 0.0013077833949234265, 'subsample': 0.7884877878009724, 'min_samples_leaf': 0.35009246925961063, 'min_samples_split': 0.42105208079195017}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:08,569] Trial 93 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 6, 'learning_rate': 0.0020742344505596194, 'subsample': 0.8968845753097007, 'min_samples_leaf': 0.37094538786846426, 'min_samples_split': 0.3958956287503249}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:08,624] Trial 94 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 6, 'learning_rate': 0.004186189224019476, 'subsample': 0.8654052629973746, 'min_samples_leaf': 0.3798069977828161, 'min_samples_split': 0.32969225801810503}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:08,677] Trial 95 finished with value: 0.5 and parameters: {'loss': 'log_loss', 'n_estimators': 7, 'learning_rate': 0.0010126677488883115, 'subsample': 0.4835702947533495, 'min_samples_leaf': 0.5298012663675332, 'min_samples_split': 0.4645561106973121}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:08,731] Trial 96 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 6, 'learning_rate': 0.0008112749526769011, 'subsample': 0.7624754764688765, 'min_samples_leaf': 0.33098731270672316, 'min_samples_split': 0.3624778286176603}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:08,779] Trial 97 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 8, 'learning_rate': 0.0019238353947267314, 'subsample': 0.8385366651400972, 'min_samples_leaf': 0.35541655192550614, 'min_samples_split': 0.38205279606960185}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:08,830] Trial 98 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 6, 'learning_rate': 0.0005870983239514454, 'subsample': 0.8167608858680356, 'min_samples_leaf': 0.34019516521226983, 'min_samples_split': 0.4095074044186524}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:08,882] Trial 99 finished with value: 1.0 and parameters: {'loss': 'exponential', 'n_estimators': 7, 'learning_rate': 0.0007646264913700547, 'subsample': 0.7773362195675494, 'min_samples_leaf': 0.3630487400806896, 'min_samples_split': 0.3757529748108531}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:08,925] Trial 100 finished with value: 0.5 and parameters: {'loss': 'log_loss', 'n_estimators': 6, 'learning_rate': 0.0015695382459827664, 'subsample': 0.5658283714561992, 'min_samples_leaf': 0.42981618435219504, 'min_samples_split': 0.48857023779777925}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:08,969] Trial 101 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 5, 'learning_rate': 0.001586339300959281, 'subsample': 0.8757196760034964, 'min_samples_leaf': 0.3389150122598661, 'min_samples_split': 0.36920381377576295}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:09,020] Trial 102 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 5, 'learning_rate': 0.0010809038724952254, 'subsample': 0.8494708763586861, 'min_samples_leaf': 0.3897406349881007, 'min_samples_split': 0.3923203732573806}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:09,071] Trial 103 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 5, 'learning_rate': 0.0009302229237189085, 'subsample': 0.8770078122636291, 'min_samples_leaf': 0.3341642388990177, 'min_samples_split': 0.3563053166830467}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:09,111] Trial 104 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 5, 'learning_rate': 0.0017948027907482523, 'subsample': 0.7917711368731405, 'min_samples_leaf': 0.3222509172460916, 'min_samples_split': 0.33742477326385184}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:09,156] Trial 105 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 6, 'learning_rate': 0.0013332762679318638, 'subsample': 0.7565170640653153, 'min_samples_leaf': 0.3455854861110831, 'min_samples_split': 0.3677193671440471}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:09,239] Trial 106 finished with value: 0.5 and parameters: {'loss': 'log_loss', 'n_estimators': 6, 'learning_rate': 0.000721276324656854, 'subsample': 0.7365716939657401, 'min_samples_leaf': 0.3687224691873752, 'min_samples_split': 0.3858521059641411}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:09,300] Trial 107 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 6, 'learning_rate': 0.001165550884309814, 'subsample': 0.8386985264432786, 'min_samples_leaf': 0.30590451875449487, 'min_samples_split': 0.40457873808750966}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:09,352] Trial 108 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 7, 'learning_rate': 0.0005611584250069648, 'subsample': 0.8168572075111029, 'min_samples_leaf': 0.3173010109100307, 'min_samples_split': 0.4323000843788945}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:09,393] Trial 109 finished with value: 0.5 and parameters: {'loss': 'log_loss', 'n_estimators': 4, 'learning_rate': 0.0008696359400336896, 'subsample': 0.7010013056154359, 'min_samples_leaf': 0.39958611923815995, 'min_samples_split': 0.45150697835542425}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:09,437] Trial 110 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 6, 'learning_rate': 0.0006473207365563822, 'subsample': 0.8562312723498678, 'min_samples_leaf': 0.38321459829108667, 'min_samples_split': 0.3494677942055519}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:09,488] Trial 111 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 8, 'learning_rate': 0.0008424203230646393, 'subsample': 0.7389596990318067, 'min_samples_leaf': 0.31363467696329506, 'min_samples_split': 0.3984036199827675}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:09,539] Trial 112 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 8, 'learning_rate': 0.0010390410180113109, 'subsample': 0.7900401959969138, 'min_samples_leaf': 0.35717078210339315, 'min_samples_split': 0.37642645147338455}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:09,591] Trial 113 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 8, 'learning_rate': 0.0009338240665242649, 'subsample': 0.7715374017398338, 'min_samples_leaf': 0.3759936475766284, 'min_samples_split': 0.4051836160825754}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:09,635] Trial 114 finished with value: 0.5 and parameters: {'loss': 'log_loss', 'n_estimators': 6, 'learning_rate': 0.0007346560250546142, 'subsample': 0.722667013995462, 'min_samples_leaf': 0.41213157640710546, 'min_samples_split': 0.41825659425508904}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:09,684] Trial 115 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 8, 'learning_rate': 0.0006350215475338799, 'subsample': 0.7493125912785078, 'min_samples_leaf': 0.34960666908717075, 'min_samples_split': 0.3563241002108242}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:09,734] Trial 116 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 6, 'learning_rate': 0.0005476986318728907, 'subsample': 0.8307116910886228, 'min_samples_leaf': 0.30006131595897645, 'min_samples_split': 0.3899382207206606}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:09,777] Trial 117 finished with value: 0.5 and parameters: {'loss': 'log_loss', 'n_estimators': 5, 'learning_rate': 0.0007969475463742814, 'subsample': 0.6646643658083533, 'min_samples_leaf': 0.6628780107173468, 'min_samples_split': 0.38310169287802015}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:09,834] Trial 118 finished with value: 1.0 and parameters: {'loss': 'exponential', 'n_estimators': 6, 'learning_rate': 0.0012716645942165137, 'subsample': 0.8028767566012673, 'min_samples_leaf': 0.32982001322922727, 'min_samples_split': 0.3718747375945998}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:09,873] Trial 119 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 3, 'learning_rate': 0.0030961222459116662, 'subsample': 0.8918792683102409, 'min_samples_leaf': 0.3359478546049384, 'min_samples_split': 0.36338114350990824}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:09,909] Trial 120 finished with value: 0.5 and parameters: {'loss': 'log_loss', 'n_estimators': 7, 'learning_rate': 0.0009961423934325639, 'subsample': 0.6870454856212455, 'min_samples_leaf': 0.3629420905844396, 'min_samples_split': 0.41227235695641296}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:09,969] Trial 121 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 6, 'learning_rate': 0.0005803891234973879, 'subsample': 0.8816263474734006, 'min_samples_leaf': 0.3873953759134389, 'min_samples_split': 0.39498335039036125}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:10,029] Trial 122 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 6, 'learning_rate': 0.0006817938007517294, 'subsample': 0.8731906995766288, 'min_samples_leaf': 0.40176798365478056, 'min_samples_split': 0.38248704592986604}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:10,079] Trial 123 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 6, 'learning_rate': 0.0008463758024493128, 'subsample': 0.8518977242680891, 'min_samples_leaf': 0.38157295403774333, 'min_samples_split': 0.3999755194230072}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:10,121] Trial 124 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 6, 'learning_rate': 0.0005130377547835658, 'subsample': 0.80869152377124, 'min_samples_leaf': 0.37117158846878223, 'min_samples_split': 0.4299162450372059}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:10,167] Trial 125 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 6, 'learning_rate': 0.0006026461019612119, 'subsample': 0.7646173105670759, 'min_samples_leaf': 0.3242835051353184, 'min_samples_split': 0.37334796936217696}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:10,205] Trial 126 finished with value: 0.5 and parameters: {'loss': 'log_loss', 'n_estimators': 6, 'learning_rate': 0.0007034582185685127, 'subsample': 0.7847336558938862, 'min_samples_leaf': 0.4230383002785139, 'min_samples_split': 0.3642905438490117}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:10,254] Trial 127 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 6, 'learning_rate': 0.0005465887245740442, 'subsample': 0.8282059724926345, 'min_samples_leaf': 0.3927367808077636, 'min_samples_split': 0.3896802294170761}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:10,309] Trial 128 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 6, 'learning_rate': 0.0007735307493183525, 'subsample': 0.8626589290963872, 'min_samples_leaf': 0.35414921716144, 'min_samples_split': 0.34152371155837186}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:10,351] Trial 129 finished with value: 0.5 and parameters: {'loss': 'log_loss', 'n_estimators': 5, 'learning_rate': 0.0006572187539858197, 'subsample': 0.8372714182900242, 'min_samples_leaf': 0.4568460328512036, 'min_samples_split': 0.3505323065322476}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:10,394] Trial 130 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 6, 'learning_rate': 0.001128358402958885, 'subsample': 0.8037894010591318, 'min_samples_leaf': 0.3445688928177551, 'min_samples_split': 0.30356756163617543}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:10,444] Trial 131 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 6, 'learning_rate': 0.0008636990636573072, 'subsample': 0.8909207410838492, 'min_samples_leaf': 0.3722348792143767, 'min_samples_split': 0.40892742582798314}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:10,494] Trial 132 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 6, 'learning_rate': 0.0009569120849094338, 'subsample': 0.8948170791928854, 'min_samples_leaf': 0.38283538123090455, 'min_samples_split': 0.4433324555737616}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:10,538] Trial 133 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 6, 'learning_rate': 0.0005050394454717905, 'subsample': 0.8674187770156041, 'min_samples_leaf': 0.40622935408256233, 'min_samples_split': 0.3785813926473097}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:10,582] Trial 134 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 6, 'learning_rate': 0.009575555671241229, 'subsample': 0.8988602000528149, 'min_samples_leaf': 0.3606152920902115, 'min_samples_split': 0.4197191588753211}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:10,618] Trial 135 finished with value: 0.5 and parameters: {'loss': 'log_loss', 'n_estimators': 6, 'learning_rate': 0.0014382930031625071, 'subsample': 0.8437497415848284, 'min_samples_leaf': 0.39462454435296174, 'min_samples_split': 0.8724531631165184}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:10,663] Trial 136 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 6, 'learning_rate': 0.0007490803377133972, 'subsample': 0.8149479737084355, 'min_samples_leaf': 0.37943970541158517, 'min_samples_split': 0.39217223507138926}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:10,716] Trial 137 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 6, 'learning_rate': 0.0006067782495263454, 'subsample': 0.7816095506865381, 'min_samples_leaf': 0.3135935169733882, 'min_samples_split': 0.3990956337674767}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:10,767] Trial 138 finished with value: 1.0 and parameters: {'loss': 'exponential', 'n_estimators': 7, 'learning_rate': 0.0009042152186077856, 'subsample': 0.7534970257577208, 'min_samples_leaf': 0.3645793454740596, 'min_samples_split': 0.4114233132166563}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:10,810] Trial 139 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 5, 'learning_rate': 0.0021997092985175737, 'subsample': 0.8610711672555336, 'min_samples_leaf': 0.41233108423334336, 'min_samples_split': 0.35729667006617283}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:10,864] Trial 140 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 7, 'learning_rate': 0.0010167390454865427, 'subsample': 0.7096408414121558, 'min_samples_leaf': 0.3094454705765226, 'min_samples_split': 0.3858805053520056}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:10,915] Trial 141 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 6, 'learning_rate': 0.0008045934428970453, 'subsample': 0.8263694559072663, 'min_samples_leaf': 0.35721834683438447, 'min_samples_split': 0.3147701182910009}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:10,970] Trial 142 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 6, 'learning_rate': 0.0012480461970220723, 'subsample': 0.84560174012179, 'min_samples_leaf': 0.3742100238469768, 'min_samples_split': 0.32158871359594376}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:11,024] Trial 143 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 4, 'learning_rate': 0.0011013649148442976, 'subsample': 0.7941193331964059, 'min_samples_leaf': 0.38854297669040083, 'min_samples_split': 0.31869031221564725}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:11,069] Trial 144 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 6, 'learning_rate': 0.0006757157544474251, 'subsample': 0.8131997495706265, 'min_samples_leaf': 0.34289603334956803, 'min_samples_split': 0.311401393465116}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:11,115] Trial 145 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 6, 'learning_rate': 0.0009669583308316398, 'subsample': 0.7346129358983581, 'min_samples_leaf': 0.35514882019208327, 'min_samples_split': 0.3289685328400069}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:11,162] Trial 146 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 8, 'learning_rate': 0.0008528327569506842, 'subsample': 0.7708750942320235, 'min_samples_leaf': 0.3303671431607343, 'min_samples_split': 0.37056247075092236}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:11,210] Trial 147 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 6, 'learning_rate': 0.0005573038400220871, 'subsample': 0.8738787751711092, 'min_samples_leaf': 0.3991889611140862, 'min_samples_split': 0.30537168540852966}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:11,259] Trial 148 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 6, 'learning_rate': 0.00076059686697185, 'subsample': 0.846769279941148, 'min_samples_leaf': 0.3688152342761834, 'min_samples_split': 0.3795635889922158}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:11,304] Trial 149 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 6, 'learning_rate': 0.001184029357298463, 'subsample': 0.7930174824174624, 'min_samples_leaf': 0.3195569232171243, 'min_samples_split': 0.39345194283239926}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:11,341] Trial 150 finished with value: 0.5 and parameters: {'loss': 'log_loss', 'n_estimators': 6, 'learning_rate': 0.000637878881000508, 'subsample': 0.8230179721852009, 'min_samples_leaf': 0.7997111205355872, 'min_samples_split': 0.40674285234130375}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:11,393] Trial 151 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 5, 'learning_rate': 0.001627520995965169, 'subsample': 0.7716771153808146, 'min_samples_leaf': 0.3373801458346631, 'min_samples_split': 0.33534880519418203}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:11,447] Trial 152 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 5, 'learning_rate': 0.0010383687859756067, 'subsample': 0.7477110435498893, 'min_samples_leaf': 0.35167191062841174, 'min_samples_split': 0.3441760036703018}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:11,500] Trial 153 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 5, 'learning_rate': 0.0009056679592437058, 'subsample': 0.7975529385741333, 'min_samples_leaf': 0.3802849828522645, 'min_samples_split': 0.3624374355775426}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:11,545] Trial 154 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 5, 'learning_rate': 0.0014410644093152411, 'subsample': 0.8733590945477804, 'min_samples_leaf': 0.3464147276663279, 'min_samples_split': 0.35208165155653603}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:11,583] Trial 155 finished with value: 0.5 and parameters: {'loss': 'log_loss', 'n_estimators': 6, 'learning_rate': 0.0012810601255768832, 'subsample': 0.5331652258312879, 'min_samples_leaf': 0.5876091840739711, 'min_samples_split': 0.3736707550092535}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:11,628] Trial 156 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 6, 'learning_rate': 0.0011654203449929458, 'subsample': 0.8380520166263074, 'min_samples_leaf': 0.3639425376152893, 'min_samples_split': 0.5939173346851246}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:11,688] Trial 157 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 6, 'learning_rate': 0.0009860085887165152, 'subsample': 0.7568839483129358, 'min_samples_leaf': 0.32523297844480814, 'min_samples_split': 0.3672636256026287}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:11,737] Trial 158 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 5, 'learning_rate': 0.0018377729559841554, 'subsample': 0.7802880459590683, 'min_samples_leaf': 0.37613571436487975, 'min_samples_split': 0.3819322504968203}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:11,785] Trial 159 finished with value: 0.5 and parameters: {'loss': 'log_loss', 'n_estimators': 7, 'learning_rate': 0.01604903336935013, 'subsample': 0.7211754364703399, 'min_samples_leaf': 0.3902994302525278, 'min_samples_split': 0.38699146807435414}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:11,893] Trial 160 finished with value: 1.0 and parameters: {'loss': 'exponential', 'n_estimators': 6, 'learning_rate': 0.000723016327536531, 'subsample': 0.8161116541214384, 'min_samples_leaf': 0.36608946619277194, 'min_samples_split': 0.4000506490730074}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:11,944] Trial 161 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 5, 'learning_rate': 0.0005870583864556503, 'subsample': 0.8608800327525011, 'min_samples_leaf': 0.3052593779683944, 'min_samples_split': 0.3617210683395755}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:12,008] Trial 162 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 5, 'learning_rate': 0.0006736849214505892, 'subsample': 0.8850711758847252, 'min_samples_leaf': 0.33421525679628883, 'min_samples_split': 0.35194106773922845}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:12,063] Trial 163 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 5, 'learning_rate': 0.0008111998485306554, 'subsample': 0.8530877385097151, 'min_samples_leaf': 0.3173570854537604, 'min_samples_split': 0.37152772100196163}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:12,106] Trial 164 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 5, 'learning_rate': 0.0005042369422857553, 'subsample': 0.8295271827908106, 'min_samples_leaf': 0.3422052367836719, 'min_samples_split': 0.3782806957364724}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:12,155] Trial 165 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 8, 'learning_rate': 0.0008887615060898412, 'subsample': 0.8998733046907559, 'min_samples_leaf': 0.3134742739745488, 'min_samples_split': 0.327196620037575}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:12,203] Trial 166 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 6, 'learning_rate': 0.0006086046338484375, 'subsample': 0.796843903199456, 'min_samples_leaf': 0.3272938734805363, 'min_samples_split': 0.4225298834844156}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:12,248] Trial 167 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 5, 'learning_rate': 0.0007078353839677026, 'subsample': 0.8567075280716187, 'min_samples_leaf': 0.38424270087197343, 'min_samples_split': 0.3572794111815665}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:12,302] Trial 168 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 6, 'learning_rate': 0.0010790968129538157, 'subsample': 0.8109665446901566, 'min_samples_leaf': 0.35854320694698383, 'min_samples_split': 0.3382174296383018}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:12,358] Trial 169 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 6, 'learning_rate': 0.0005485801507613548, 'subsample': 0.7686783605165318, 'min_samples_leaf': 0.37251974077445094, 'min_samples_split': 0.34626166472175485}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:12,404] Trial 170 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 6, 'learning_rate': 0.0007754226599250161, 'subsample': 0.8376823728207742, 'min_samples_leaf': 0.3478011256919455, 'min_samples_split': 0.30943302805796385}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:12,450] Trial 171 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 6, 'learning_rate': 0.000631458344605238, 'subsample': 0.8252042415798642, 'min_samples_leaf': 0.3945110639064497, 'min_samples_split': 0.38943539910965386}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:12,498] Trial 172 finished with value: 0.5 and parameters: {'loss': 'log_loss', 'n_estimators': 6, 'learning_rate': 0.0005864514185830619, 'subsample': 0.5852108984646246, 'min_samples_leaf': 0.38334039126183894, 'min_samples_split': 0.3979235269828849}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:12,550] Trial 173 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 6, 'learning_rate': 0.0005560018525672423, 'subsample': 0.8790755628511834, 'min_samples_leaf': 0.38795279198151494, 'min_samples_split': 0.3809491125802969}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:12,599] Trial 174 finished with value: 0.5 and parameters: {'loss': 'log_loss', 'n_estimators': 6, 'learning_rate': 0.0006832155498588348, 'subsample': 0.7865362479014992, 'min_samples_leaf': 0.405713096418055, 'min_samples_split': 0.37279710440596453}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:12,649] Trial 175 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 6, 'learning_rate': 0.0008537165287160705, 'subsample': 0.8630496794850433, 'min_samples_leaf': 0.3211288430075309, 'min_samples_split': 0.41171577073263504}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:12,687] Trial 176 finished with value: 0.5 and parameters: {'loss': 'log_loss', 'n_estimators': 6, 'learning_rate': 0.0009554811393246152, 'subsample': 0.4370641244628629, 'min_samples_leaf': 0.3769637464852462, 'min_samples_split': 0.36478246276972776}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:12,746] Trial 177 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 6, 'learning_rate': 0.0007673984232129977, 'subsample': 0.8059193016987632, 'min_samples_leaf': 0.368504699489949, 'min_samples_split': 0.38844008249584194}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:12,800] Trial 178 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 5, 'learning_rate': 0.0005383781873066253, 'subsample': 0.837936831459523, 'min_samples_leaf': 0.396257158652753, 'min_samples_split': 0.40266305260075413}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:12,851] Trial 179 finished with value: 0.5 and parameters: {'loss': 'log_loss', 'n_estimators': 6, 'learning_rate': 0.0006376567344531643, 'subsample': 0.40438343785526293, 'min_samples_leaf': 0.30741750558500913, 'min_samples_split': 0.37784379068810275}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:12,902] Trial 180 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 7, 'learning_rate': 0.0008277496128765447, 'subsample': 0.7384888305374414, 'min_samples_leaf': 0.35930991196975887, 'min_samples_split': 0.3914650274095706}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:12,955] Trial 181 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 6, 'learning_rate': 0.0005491721755907462, 'subsample': 0.8958630942682604, 'min_samples_leaf': 0.38849951671827526, 'min_samples_split': 0.4126497720201497}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:13,008] Trial 182 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 6, 'learning_rate': 0.0005072830142403192, 'subsample': 0.8774465475078169, 'min_samples_leaf': 0.41145038093655617, 'min_samples_split': 0.43392081151042533}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:13,081] Trial 183 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 6, 'learning_rate': 0.000704391207638859, 'subsample': 0.8526800575954575, 'min_samples_leaf': 0.377334700338282, 'min_samples_split': 0.40503680006131615}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:13,171] Trial 184 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 6, 'learning_rate': 0.0005954118823865429, 'subsample': 0.8799824905787533, 'min_samples_leaf': 0.402345445883858, 'min_samples_split': 0.3939327143607551}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:13,239] Trial 185 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 6, 'learning_rate': 0.0009961117156176266, 'subsample': 0.8145282067503756, 'min_samples_leaf': 0.3384041924774285, 'min_samples_split': 0.36863715692772686}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:13,296] Trial 186 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 6, 'learning_rate': 0.000640234478568263, 'subsample': 0.8984842521827393, 'min_samples_leaf': 0.36988400309324015, 'min_samples_split': 0.38319783274429103}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:13,345] Trial 187 finished with value: 0.5 and parameters: {'loss': 'log_loss', 'n_estimators': 6, 'learning_rate': 0.0005081631208622143, 'subsample': 0.7866154926839912, 'min_samples_leaf': 0.39535391662575314, 'min_samples_split': 0.41963002191152976}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:13,402] Trial 188 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 6, 'learning_rate': 0.001120028728784261, 'subsample': 0.7628848624495829, 'min_samples_leaf': 0.3505040778939266, 'min_samples_split': 0.30055457266881264}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:13,457] Trial 189 finished with value: 0.5 and parameters: {'loss': 'exponential', 'n_estimators': 8, 'learning_rate': 0.0009390885991009555, 'subsample': 0.8631824914687998, 'min_samples_leaf': 0.5640248040351392, 'min_samples_split': 0.3205271477376546}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:13,506] Trial 190 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 5, 'learning_rate': 0.0007355047796594094, 'subsample': 0.8354740246044021, 'min_samples_leaf': 0.38329571784413086, 'min_samples_split': 0.5325881671439527}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:13,551] Trial 191 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 6, 'learning_rate': 0.002634446230301396, 'subsample': 0.8019764013266022, 'min_samples_leaf': 0.36212576615566067, 'min_samples_split': 0.35517109311810113}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:13,588] Trial 192 finished with value: 0.5 and parameters: {'loss': 'log_loss', 'n_estimators': 6, 'learning_rate': 0.0008179179312155187, 'subsample': 0.3550715522280191, 'min_samples_leaf': 0.3756576604559734, 'min_samples_split': 0.34950899450184003}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:13,644] Trial 193 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 6, 'learning_rate': 0.02072721218049702, 'subsample': 0.778112301227953, 'min_samples_leaf': 0.3312000886021489, 'min_samples_split': 0.33322537236963107}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:13,690] Trial 194 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 4, 'learning_rate': 0.0005928255218448142, 'subsample': 0.8213253920456848, 'min_samples_leaf': 0.363692909467015, 'min_samples_split': 0.36042757323319924}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:13,736] Trial 195 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 6, 'learning_rate': 0.0006584095855847269, 'subsample': 0.8480603754177048, 'min_samples_leaf': 0.35146370454095877, 'min_samples_split': 0.34346350796211006}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:13,781] Trial 196 finished with value: 0.5 and parameters: {'loss': 'log_loss', 'n_estimators': 6, 'learning_rate': 0.0008876960044566826, 'subsample': 0.7970019691465312, 'min_samples_leaf': 0.4196979406380013, 'min_samples_split': 0.3761190430261178}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:13,848] Trial 197 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 6, 'learning_rate': 0.001043766527547505, 'subsample': 0.8233111922616112, 'min_samples_leaf': 0.3156553354610395, 'min_samples_split': 0.401573251471281}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:13,893] Trial 198 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 6, 'learning_rate': 0.0013604929775980627, 'subsample': 0.8687955675384411, 'min_samples_leaf': 0.38935502977063, 'min_samples_split': 0.38494143514609297}. Best is trial 31 with value: 1.0.\n",
      "[I 2025-03-29 17:40:13,949] Trial 199 finished with value: 1.0 and parameters: {'loss': 'log_loss', 'n_estimators': 6, 'learning_rate': 0.0007543504285336957, 'subsample': 0.7654641258505743, 'min_samples_leaf': 0.36799245310920137, 'min_samples_split': 0.5068294471678322}. Best is trial 31 with value: 1.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'n_estimators', 'learning_rate', 'subsample', 'min_samples_leaf', 'min_samples_split'] GradientBoostingClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 17:40:57,251] A new study created in memory with name: no-name-3152180d-c593-4627-8a74-c602e7711fec\n",
      "[I 2025-03-29 17:40:57,336] Trial 0 finished with value: 1.0 and parameters: {'C': 0.5816497547216986}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:40:57,415] Trial 1 finished with value: 1.0 and parameters: {'C': 0.7407601348228648}. Best is trial 0 with value: 1.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run intrigued-shad-651 at: http://127.0.0.1:1500/#/experiments/2/runs/af1104e55151482a91931574327931ed\n",
      "🧪 View experiment at: http://127.0.0.1:1500/#/experiments/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-29 17:40:57,503] Trial 2 finished with value: 1.0 and parameters: {'C': 0.11406310954455567}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:40:57,644] Trial 3 finished with value: 1.0 and parameters: {'C': 0.07001285638120958}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:40:57,724] Trial 4 finished with value: 1.0 and parameters: {'C': 0.5591267724412591}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:40:57,805] Trial 5 finished with value: 1.0 and parameters: {'C': 0.9515725763471286}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:40:57,885] Trial 6 finished with value: 1.0 and parameters: {'C': 0.18985488971148212}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:40:57,996] Trial 7 finished with value: 1.0 and parameters: {'C': 0.9461463316820526}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:40:58,077] Trial 8 finished with value: 1.0 and parameters: {'C': 0.258927842056356}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:40:58,172] Trial 9 finished with value: 0.9994913530010172 and parameters: {'C': 0.09720415125837922}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:40:58,267] Trial 10 finished with value: 1.0 and parameters: {'C': 0.4569769402348537}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:40:58,371] Trial 11 finished with value: 1.0 and parameters: {'C': 0.7057359193955879}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:40:58,470] Trial 12 finished with value: 1.0 and parameters: {'C': 0.736359519206504}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:40:58,564] Trial 13 finished with value: 1.0 and parameters: {'C': 0.7470963778181267}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:40:58,677] Trial 14 finished with value: 1.0 and parameters: {'C': 0.45373072216872634}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:40:58,791] Trial 15 finished with value: 1.0 and parameters: {'C': 0.5911157985745}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:40:58,874] Trial 16 finished with value: 1.0 and parameters: {'C': 0.35170540500580083}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:40:58,968] Trial 17 finished with value: 1.0 and parameters: {'C': 0.8419943482545864}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:40:59,071] Trial 18 finished with value: 1.0 and parameters: {'C': 0.6340098790246607}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:40:59,172] Trial 19 finished with value: 1.0 and parameters: {'C': 0.849423478327674}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:40:59,273] Trial 20 finished with value: 1.0 and parameters: {'C': 0.3426913449226194}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:40:59,380] Trial 21 finished with value: 0.9059266679899759 and parameters: {'C': 0.004007300377968426}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:40:59,476] Trial 22 finished with value: 1.0 and parameters: {'C': 0.5076325562826038}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:40:59,576] Trial 23 finished with value: 1.0 and parameters: {'C': 0.6316725715420053}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:40:59,678] Trial 24 finished with value: 1.0 and parameters: {'C': 0.36957622502947474}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:40:59,777] Trial 25 finished with value: 1.0 and parameters: {'C': 0.6795530182389812}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:40:59,871] Trial 26 finished with value: 1.0 and parameters: {'C': 0.8315421353236873}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:40:59,959] Trial 27 finished with value: 1.0 and parameters: {'C': 0.2541957880522395}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:00,065] Trial 28 finished with value: 1.0 and parameters: {'C': 0.49872949338850514}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:00,158] Trial 29 finished with value: 1.0 and parameters: {'C': 0.11771519821575638}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:00,257] Trial 30 finished with value: 1.0 and parameters: {'C': 0.802565466055457}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:00,354] Trial 31 finished with value: 0.8759413070987272 and parameters: {'C': 0.002261079028347046}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:00,449] Trial 32 finished with value: 0.9994913530010172 and parameters: {'C': 0.09853176819890815}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:00,548] Trial 33 finished with value: 1.0 and parameters: {'C': 0.19778020714128558}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:00,640] Trial 34 finished with value: 1.0 and parameters: {'C': 0.5610645094949631}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:00,731] Trial 35 finished with value: 1.0 and parameters: {'C': 0.9581451052712847}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:00,818] Trial 36 finished with value: 0.9984740590030519 and parameters: {'C': 0.0535261911096149}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:00,917] Trial 37 finished with value: 1.0 and parameters: {'C': 0.15861217923297585}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:01,009] Trial 38 finished with value: 1.0 and parameters: {'C': 0.24823806063126858}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:01,104] Trial 39 finished with value: 1.0 and parameters: {'C': 0.18054785653360167}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:01,194] Trial 40 finished with value: 1.0 and parameters: {'C': 0.410010921543763}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:01,281] Trial 41 finished with value: 1.0 and parameters: {'C': 0.5380245810298153}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:01,365] Trial 42 finished with value: 1.0 and parameters: {'C': 0.9070948338924978}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:01,445] Trial 43 finished with value: 1.0 and parameters: {'C': 0.6691891943497223}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:01,524] Trial 44 finished with value: 1.0 and parameters: {'C': 0.5980380286314443}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:01,645] Trial 45 finished with value: 1.0 and parameters: {'C': 0.770447161050875}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:01,845] Trial 46 finished with value: 1.0 and parameters: {'C': 0.4427095589889773}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:01,977] Trial 47 finished with value: 1.0 and parameters: {'C': 0.7280109799824104}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:02,073] Trial 48 finished with value: 1.0 and parameters: {'C': 0.3092088033550677}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:02,157] Trial 49 finished with value: 0.996439471007121 and parameters: {'C': 0.06076757517290134}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:02,240] Trial 50 finished with value: 1.0 and parameters: {'C': 0.5058460833825597}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:02,322] Trial 51 finished with value: 1.0 and parameters: {'C': 0.9055286836971418}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:02,407] Trial 52 finished with value: 1.0 and parameters: {'C': 0.9000757268004155}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:02,493] Trial 53 finished with value: 1.0 and parameters: {'C': 0.6153155571596578}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:02,575] Trial 54 finished with value: 1.0 and parameters: {'C': 0.6765712683999384}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:02,656] Trial 55 finished with value: 1.0 and parameters: {'C': 0.553998507293811}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:02,736] Trial 56 finished with value: 1.0 and parameters: {'C': 0.9866148112603649}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:02,818] Trial 57 finished with value: 1.0 and parameters: {'C': 0.7750649396805906}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:02,917] Trial 58 finished with value: 1.0 and parameters: {'C': 0.41006776870728784}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:03,007] Trial 59 finished with value: 1.0 and parameters: {'C': 0.704173407536631}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:03,106] Trial 60 finished with value: 1.0 and parameters: {'C': 0.2995130837935018}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:03,195] Trial 61 finished with value: 1.0 and parameters: {'C': 0.14181268355582025}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:03,282] Trial 62 finished with value: 0.9979654120040692 and parameters: {'C': 0.054717840536020995}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:03,397] Trial 63 finished with value: 1.0 and parameters: {'C': 0.22166117066578084}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:03,475] Trial 64 finished with value: 0.9989827060020346 and parameters: {'C': 0.08060146997904391}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:03,545] Trial 65 finished with value: 1.0 and parameters: {'C': 0.12579037558764158}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:03,622] Trial 66 finished with value: 1.0 and parameters: {'C': 0.8672543872774119}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:03,707] Trial 67 finished with value: 1.0 and parameters: {'C': 0.6445952765483509}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:03,784] Trial 68 finished with value: 1.0 and parameters: {'C': 0.47524919979478536}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:03,867] Trial 69 finished with value: 0.9669379450661242 and parameters: {'C': 0.019080571327048212}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:03,945] Trial 70 finished with value: 1.0 and parameters: {'C': 0.18582016684081865}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:04,022] Trial 71 finished with value: 1.0 and parameters: {'C': 0.9931101466922992}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:04,101] Trial 72 finished with value: 1.0 and parameters: {'C': 0.9479915000391802}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:04,179] Trial 73 finished with value: 1.0 and parameters: {'C': 0.8281382200396594}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:04,254] Trial 74 finished with value: 1.0 and parameters: {'C': 0.5785622563490803}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:04,330] Trial 75 finished with value: 1.0 and parameters: {'C': 0.9420797953532996}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:04,400] Trial 76 finished with value: 1.0 and parameters: {'C': 0.8639920509861234}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:04,474] Trial 77 finished with value: 1.0 and parameters: {'C': 0.808105892850089}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:04,556] Trial 78 finished with value: 1.0 and parameters: {'C': 0.7080649175045117}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:04,696] Trial 79 finished with value: 0.9776195320447609 and parameters: {'C': 0.02829201102010634}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:04,778] Trial 80 finished with value: 1.0 and parameters: {'C': 0.529246795534168}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:04,859] Trial 81 finished with value: 0.9994913530010172 and parameters: {'C': 0.09573783058329763}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:04,968] Trial 82 finished with value: 1.0 and parameters: {'C': 0.15157880405339064}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:05,075] Trial 83 finished with value: 1.0 and parameters: {'C': 0.22923040515768667}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:05,196] Trial 84 finished with value: 1.0 and parameters: {'C': 0.26301250333475723}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:05,299] Trial 85 finished with value: 1.0 and parameters: {'C': 0.11527941542685173}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:05,400] Trial 86 finished with value: 1.0 and parameters: {'C': 0.37420292884572387}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:05,505] Trial 87 finished with value: 1.0 and parameters: {'C': 0.8817447791244208}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:05,601] Trial 88 finished with value: 1.0 and parameters: {'C': 0.9224930111445655}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:05,691] Trial 89 finished with value: 1.0 and parameters: {'C': 0.966077707694798}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:05,791] Trial 90 finished with value: 1.0 and parameters: {'C': 0.16804336999703462}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:05,909] Trial 91 finished with value: 1.0 and parameters: {'C': 0.45601156381396174}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:06,023] Trial 92 finished with value: 1.0 and parameters: {'C': 0.30481624791204043}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:06,105] Trial 93 finished with value: 1.0 and parameters: {'C': 0.20021548090708297}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:06,181] Trial 94 finished with value: 1.0 and parameters: {'C': 0.5997813754070079}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:06,260] Trial 95 finished with value: 1.0 and parameters: {'C': 0.5295077245513499}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:06,338] Trial 96 finished with value: 1.0 and parameters: {'C': 0.2731978298398863}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:06,416] Trial 97 finished with value: 1.0 and parameters: {'C': 0.643996357593758}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:06,496] Trial 98 finished with value: 1.0 and parameters: {'C': 0.767791187807305}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:06,571] Trial 99 finished with value: 1.0 and parameters: {'C': 0.4775174545388906}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:06,649] Trial 100 finished with value: 1.0 and parameters: {'C': 0.4108228966433639}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:06,727] Trial 101 finished with value: 1.0 and parameters: {'C': 0.7407922266626945}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:06,811] Trial 102 finished with value: 1.0 and parameters: {'C': 0.6238404450838302}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:06,903] Trial 103 finished with value: 1.0 and parameters: {'C': 0.6578566075936156}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:06,985] Trial 104 finished with value: 1.0 and parameters: {'C': 0.5859194352158963}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:07,077] Trial 105 finished with value: 1.0 and parameters: {'C': 0.5596350740142463}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:07,177] Trial 106 finished with value: 1.0 and parameters: {'C': 0.6962873732568998}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:07,265] Trial 107 finished with value: 1.0 and parameters: {'C': 0.3368406350991281}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:07,359] Trial 108 finished with value: 1.0 and parameters: {'C': 0.13402153964310395}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:07,455] Trial 109 finished with value: 0.9989827060020346 and parameters: {'C': 0.07542589761482056}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:07,537] Trial 110 finished with value: 1.0 and parameters: {'C': 0.723129478959583}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:07,619] Trial 111 finished with value: 1.0 and parameters: {'C': 0.803665548018308}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:07,717] Trial 112 finished with value: 0.991353001017294 and parameters: {'C': 0.03948895013318163}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:07,806] Trial 113 finished with value: 1.0 and parameters: {'C': 0.7586415810958838}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:07,900] Trial 114 finished with value: 1.0 and parameters: {'C': 0.7871201415343304}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:07,992] Trial 115 finished with value: 1.0 and parameters: {'C': 0.6926968786225904}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:08,075] Trial 116 finished with value: 1.0 and parameters: {'C': 0.8243701232286366}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:08,157] Trial 117 finished with value: 1.0 and parameters: {'C': 0.9745884706016196}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:08,256] Trial 118 finished with value: 0.9994913530010172 and parameters: {'C': 0.09919853033303272}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:08,335] Trial 119 finished with value: 1.0 and parameters: {'C': 0.8477922350177085}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:08,412] Trial 120 finished with value: 1.0 and parameters: {'C': 0.5105147324486021}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:08,495] Trial 121 finished with value: 1.0 and parameters: {'C': 0.9348139874854928}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:08,582] Trial 122 finished with value: 1.0 and parameters: {'C': 0.7320573832111659}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:08,666] Trial 123 finished with value: 1.0 and parameters: {'C': 0.6689819812568111}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:08,741] Trial 124 finished with value: 1.0 and parameters: {'C': 0.7524679465138826}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:08,826] Trial 125 finished with value: 1.0 and parameters: {'C': 0.2158133656257889}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:08,916] Trial 126 finished with value: 1.0 and parameters: {'C': 0.8828183527097632}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:08,999] Trial 127 finished with value: 1.0 and parameters: {'C': 0.7131265962644247}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:09,077] Trial 128 finished with value: 1.0 and parameters: {'C': 0.6189224803475182}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:09,149] Trial 129 finished with value: 1.0 and parameters: {'C': 0.7831781223820947}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:09,226] Trial 130 finished with value: 1.0 and parameters: {'C': 0.9193022562772192}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:09,319] Trial 131 finished with value: 1.0 and parameters: {'C': 0.39134868162448544}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:09,409] Trial 132 finished with value: 1.0 and parameters: {'C': 0.5409474778628821}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:09,483] Trial 133 finished with value: 0.8551028045885749 and parameters: {'C': 0.0009574810990009286}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:09,561] Trial 134 finished with value: 1.0 and parameters: {'C': 0.5758080515163679}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:09,637] Trial 135 finished with value: 1.0 and parameters: {'C': 0.44173514331106534}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:09,713] Trial 136 finished with value: 1.0 and parameters: {'C': 0.49710701508869626}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:09,807] Trial 137 finished with value: 1.0 and parameters: {'C': 0.23990930763642643}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:09,892] Trial 138 finished with value: 1.0 and parameters: {'C': 0.4833592714512278}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:09,967] Trial 139 finished with value: 0.9994913530010172 and parameters: {'C': 0.1714566235378113}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:10,043] Trial 140 finished with value: 1.0 and parameters: {'C': 0.4614265368194513}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:10,120] Trial 141 finished with value: 1.0 and parameters: {'C': 0.5196344573126337}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:10,202] Trial 142 finished with value: 1.0 and parameters: {'C': 0.6010574505448747}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:10,318] Trial 143 finished with value: 1.0 and parameters: {'C': 0.42577700124523093}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:10,418] Trial 144 finished with value: 1.0 and parameters: {'C': 0.5551206767361677}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:10,506] Trial 145 finished with value: 1.0 and parameters: {'C': 0.3631509277931258}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:10,595] Trial 146 finished with value: 1.0 and parameters: {'C': 0.6389621177095772}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:10,682] Trial 147 finished with value: 1.0 and parameters: {'C': 0.6737437601883242}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:10,778] Trial 148 finished with value: 1.0 and parameters: {'C': 0.2816063373860004}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:10,869] Trial 149 finished with value: 0.9923702950152594 and parameters: {'C': 0.06468540738207662}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:10,967] Trial 150 finished with value: 0.9994913530010172 and parameters: {'C': 0.10459872395543679}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:11,047] Trial 151 finished with value: 1.0 and parameters: {'C': 0.33658389512899245}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:11,139] Trial 152 finished with value: 1.0 and parameters: {'C': 0.20128630617137766}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:11,237] Trial 153 finished with value: 1.0 and parameters: {'C': 0.3847334938550534}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:11,318] Trial 154 finished with value: 1.0 and parameters: {'C': 0.9995699460389528}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:11,473] Trial 155 finished with value: 1.0 and parameters: {'C': 0.7461879724931244}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:11,572] Trial 156 finished with value: 1.0 and parameters: {'C': 0.4289666907447263}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:11,658] Trial 157 finished with value: 1.0 and parameters: {'C': 0.5756247344863465}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:11,741] Trial 158 finished with value: 1.0 and parameters: {'C': 0.31362956721887914}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:11,826] Trial 159 finished with value: 0.9994913530010172 and parameters: {'C': 0.13776697039483587}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:11,902] Trial 160 finished with value: 1.0 and parameters: {'C': 0.6872673516768204}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:11,980] Trial 161 finished with value: 1.0 and parameters: {'C': 0.9482641889870541}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:12,055] Trial 162 finished with value: 1.0 and parameters: {'C': 0.8031736549688858}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:12,139] Trial 163 finished with value: 1.0 and parameters: {'C': 0.9743187176769033}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:12,214] Trial 164 finished with value: 1.0 and parameters: {'C': 0.8448920810633752}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:12,288] Trial 165 finished with value: 1.0 and parameters: {'C': 0.9092666103280186}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:12,360] Trial 166 finished with value: 1.0 and parameters: {'C': 0.8854351375772715}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:12,441] Trial 167 finished with value: 1.0 and parameters: {'C': 0.7195322185440701}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:12,512] Trial 168 finished with value: 1.0 and parameters: {'C': 0.7807352904620375}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:12,596] Trial 169 finished with value: 1.0 and parameters: {'C': 0.5410585107344168}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:12,678] Trial 170 finished with value: 1.0 and parameters: {'C': 0.4884311302530743}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:12,761] Trial 171 finished with value: 1.0 and parameters: {'C': 0.6125603596382769}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:12,840] Trial 172 finished with value: 1.0 and parameters: {'C': 0.5835108125886483}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:12,915] Trial 173 finished with value: 1.0 and parameters: {'C': 0.6539342273754903}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:12,999] Trial 174 finished with value: 1.0 and parameters: {'C': 0.6255063734045074}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:13,085] Trial 175 finished with value: 0.9888097660223805 and parameters: {'C': 0.03833937456729377}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:13,165] Trial 176 finished with value: 0.9994913530010172 and parameters: {'C': 0.08341396762306291}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:13,244] Trial 177 finished with value: 1.0 and parameters: {'C': 0.7356584630418556}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:13,326] Trial 178 finished with value: 1.0 and parameters: {'C': 0.7549717527970616}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:13,404] Trial 179 finished with value: 1.0 and parameters: {'C': 0.820719760572973}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:13,487] Trial 180 finished with value: 1.0 and parameters: {'C': 0.25551478318347104}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:13,568] Trial 181 finished with value: 1.0 and parameters: {'C': 0.704726736155704}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:13,655] Trial 182 finished with value: 1.0 and parameters: {'C': 0.854957298948418}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:13,733] Trial 183 finished with value: 1.0 and parameters: {'C': 0.5981901166363713}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:13,810] Trial 184 finished with value: 1.0 and parameters: {'C': 0.7921200611007313}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:13,886] Trial 185 finished with value: 1.0 and parameters: {'C': 0.5588225279140229}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:13,969] Trial 186 finished with value: 0.9994913530010172 and parameters: {'C': 0.12068495326172915}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:14,048] Trial 187 finished with value: 1.0 and parameters: {'C': 0.7665635669824572}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:14,128] Trial 188 finished with value: 1.0 and parameters: {'C': 0.9307758153331308}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:14,205] Trial 189 finished with value: 1.0 and parameters: {'C': 0.955937716793825}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:14,288] Trial 190 finished with value: 1.0 and parameters: {'C': 0.15961778756785827}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:14,374] Trial 191 finished with value: 1.0 and parameters: {'C': 0.35178580573827206}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:14,457] Trial 192 finished with value: 1.0 and parameters: {'C': 0.6707749474639804}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:14,543] Trial 193 finished with value: 1.0 and parameters: {'C': 0.29074803466144433}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:14,621] Trial 194 finished with value: 1.0 and parameters: {'C': 0.4654124575395725}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:14,703] Trial 195 finished with value: 1.0 and parameters: {'C': 0.32231387478950757}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:14,781] Trial 196 finished with value: 1.0 and parameters: {'C': 0.5135535553298056}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:14,863] Trial 197 finished with value: 1.0 and parameters: {'C': 0.4035133053996413}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:14,938] Trial 198 finished with value: 1.0 and parameters: {'C': 0.22883560340116182}. Best is trial 0 with value: 1.0.\n",
      "[I 2025-03-29 17:41:15,022] Trial 199 finished with value: 1.0 and parameters: {'C': 0.6404113585018179}. Best is trial 0 with value: 1.0.\n",
      "[W 2025-03-29 17:41:15,024] The length of params must be greater than 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C'] LogisticRegression\n",
      "🏃 View run bald-snake-333 at: http://127.0.0.1:1500/#/experiments/3/runs/d4c09366da384380bce89ea66ebadf17\n",
      "🧪 View experiment at: http://127.0.0.1:1500/#/experiments/3\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(uri='http://127.0.0.1:1500')\n",
    "best_models = {}\n",
    "\n",
    "def evaluate(actual,prediction):\n",
    "  return {\n",
    "          'roc_score':roc_auc_score(actual,prediction),\n",
    "          'balance_accuracy_score':balanced_accuracy_score(actual,prediction)\n",
    "          }\n",
    "\n",
    "\n",
    "for index,model in enumerate([model for model in top_models]):\n",
    "  model_name = model().__class__.__name__\n",
    "  experiment = mlflow.set_experiment(experiment_name=f'experiement_{model_name}')\n",
    "\n",
    "  study = optuna.create_study(direction=\"maximize\")\n",
    "  study.optimize(objectives[model_name], n_trials=200)\n",
    "\n",
    "  params = study.best_params\n",
    "  best_models[model_name] =  {'score':study.best_value,\n",
    "                                              'params':study.best_params,\n",
    "                                              'model':None}\n",
    "  params_list = list(study.best_params.keys())\n",
    "\n",
    "  print(params_list,model_name)\n",
    "\n",
    "  plot_contour_fig = optuna.visualization.plot_contour(study, params=params_list)\n",
    "  plot_parallel_coordinate_fig = optuna.visualization.plot_parallel_coordinate(study, params=params_list)\n",
    "  plot_optimization_history_fig = optuna.visualization.plot_optimization_history(study)\n",
    "\n",
    "  with mlflow.start_run(experiment_id=experiment.experiment_id):\n",
    "\n",
    "    model = model(**params)\n",
    "    model.fit(X,y)\n",
    "    best_models[model_name]['model'] = model\n",
    "    predict = model.predict(X)\n",
    "\n",
    "    mlflow.log_param(\"models score\", study.best_value)\n",
    "    mlflow.log_metrics(evaluate(y,predict))\n",
    "    mlflow.log_params(model.get_params())\n",
    "    mlflow.log_figure(plot_contour_fig, \"plot_contour_fig.png\")\n",
    "    mlflow.log_figure(plot_parallel_coordinate_fig, \"plot_parallel_coordinate_fig.png\")\n",
    "    mlflow.log_figure(plot_optimization_history_fig, \"plot_optimization_history_fig.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = sorted(best_models.items(),key=lambda item:item[1]['score'],reverse=True)\n",
    "best_model = [model[-1]['model'] for model in models][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion=&#x27;entropy&#x27;, max_depth=4, max_features=&#x27;sqrt&#x27;,\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_samples_leaf=1,\n",
       "                       min_samples_split=0.3694658609314691,\n",
       "                       min_weight_fraction_leaf=0.0, monotonic_cst=None,\n",
       "                       n_estimators=225, n_jobs=None, oob_score=False,\n",
       "                       random_state=None, verbose=0, warm_start=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomForestClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion=&#x27;entropy&#x27;, max_depth=4, max_features=&#x27;sqrt&#x27;,\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_samples_leaf=1,\n",
       "                       min_samples_split=0.3694658609314691,\n",
       "                       min_weight_fraction_leaf=0.0, monotonic_cst=None,\n",
       "                       n_estimators=225, n_jobs=None, oob_score=False,\n",
       "                       random_state=None, verbose=0, warm_start=False)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='entropy', max_depth=4, max_features='sqrt',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_samples_leaf=1,\n",
       "                       min_samples_split=0.3694658609314691,\n",
       "                       min_weight_fraction_leaf=0.0, monotonic_cst=None,\n",
       "                       n_estimators=225, n_jobs=None, oob_score=False,\n",
       "                       random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
